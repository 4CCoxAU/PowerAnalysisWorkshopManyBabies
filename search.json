[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop on Data Simulation & Power Analysis",
    "section": "",
    "text": "Welcome! This website will form the basis of the 2024 ManyBabies workshop on Data Simulation & Power Analysis. Before we start, I would like to emphasise that this workshop has grown out of discussion with lots of different people and is a true collaborative effort, which accords nicely with the general philosophy of ManyBabies projects. The approach to data simulation and power analysis explored here is closely associated with the data analysis team on the ManyBabies5 project (https://manybabies.org/MB5/). This series of meetings among researchers on the data analysis team was a fundamentally exploratory process being guided by a what-if mindset; a big thanks goes to Martin Zettersten, Michaela DeBolt, Jessica Kosie and George Kachergis for the fun times and interactions that shaped my approach to simulation-based power analyses. All code and materials have been written by Christopher Cox at Aarhus University, and I take full responsibility for any errors!\nFor example, we explored questions, such as: How do predictors with two or three levels impact the power to detect an effect on infant looking times? What is the optimal balance between various practical constraints (e.g., an upper bound on the number of stimulus items that infants can attend to) and statistical inference (e.g., how much of a decrease in power are we willing to accept based on the above constraints)? Can these results inform the experimental design in some way and improve chances of replicability?\nThis workshop assumes a little literacy in R and linear mixed-effects models, but I have attempted to make these subjects as accessible as possible. If you are interested in gaining hands-on pracical experience with the code, then feel free to download the following .Rmd files with the code, so that you can get a better idea of what each code snippet does and can manipulate them according to your own needs and studies.\nI hope that this will be fun experience and useful exploration of data simulation, power analysis, statistical modelling and programming, and if you have any questions, big or small, feel free to contact me on chris[dot]mm[dot]cox@gmail.com.\nHere is a a video of the lecture.\nThe ManyBabies Team would like to get your thoughts on the workshop as well as gauge interest in future events. Your feedback is greatly appreciated: https://tinyurl.com/MB-Power\n\n\nDownload 01_ExerciseDataSimulation.Rmd\n\n\nDownload 02_SimulationBasedPowerAnalysis.Rmd\n\n\nDownload 03_GridSearch.Rmd",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "content/FurtherResources.html",
    "href": "content/FurtherResources.html",
    "title": "Further Resources",
    "section": "",
    "text": "Thank you so much to the Teaching, Training and Open Science Committee at ManyBabies for supporting the creation of this workshop! I take full responsibility for all mistakes. I have taken inspiration from the following resources and would recommend them for everyone who is interested in this topic:\n\nWorkshop on Bayesian modelling and priors.\nDeBruine, L. M., & Barr, D. J. (2021). Understanding mixed-effects models through data simulation. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920965119.\nKoch, T., Pargent, F., Kleine, A. K., Lermer, E., & Gaube, S. (2023). A Tutorial on Tailored Simulation-Based Power Analysis for Experimental Designs with Generalized Linear Mixed Models. PsyArxiv: https://osf.io/preprints/psyarxiv/rpjem/.\nLakens, D., & Caldwell, A. R. (2021). Simulation-based power analysis for factorial analysis of variance designs. Advances in Methods and Practices in Psychological Science, 4(1), 2515245920951503.\nRPsychologist Website to explore meaning of effect sizes.\nMani, N., Schreiner, M. S., Brase, J., Köhler, K., Strassen, K., Postin, D., & Schultze, T. (2021). Sequential Bayes Factor designs in developmental research: studies on early word learning. Developmental Science, e13097.\nZhang, Z. (2014). Monte Carlo based statistical power analysis for mediation models: Methods and software. Behavior research methods, 46, 1184-1198.",
    "crumbs": [
      "Further Resources"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html",
    "href": "content/SimulationBasedPowerAnalysis_02.html",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "",
    "text": "Up until now, we have relied solely on our intuitions about infant looking times based on our experience with conducting infant experiments. This strategy introduces lots of assumptions into the simulation process and creates a multiverse of different parameter settings that have real effects on power analyses. In this section, we consider how to improve our data simulation process by capitalising on cumulative science efforts, such as using effect size estimates from meta-analyses and multi-lab replication studies.\nFor the IDS preference effect, for example, we can thank the ManyBabies community for conducting both a multi-lab replication study and a community-augmented meta-analysis on infants’ preference to attend to IDS over ADS (ManyBabies Consortium, 2020; Zettersten, Cox, Bergmann, et al., 2023). By synthesising data across such a wide variety of experimental designs, participants and stimuli, we now have a fairly good estimate of the overall magnitude of the IDS preference effect. Both sources of evidence converge on an effect size of ~0.35 with 95% CI of [0.16; 0.47]. This section delves into the realm of effect sizes and teaches you how to implement a power analysis based on an effect size estimate.",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html#cumulative-science-and-prior-knowledge",
    "href": "content/SimulationBasedPowerAnalysis_02.html#cumulative-science-and-prior-knowledge",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "",
    "text": "Up until now, we have relied solely on our intuitions about infant looking times based on our experience with conducting infant experiments. This strategy introduces lots of assumptions into the simulation process and creates a multiverse of different parameter settings that have real effects on power analyses. In this section, we consider how to improve our data simulation process by capitalising on cumulative science efforts, such as using effect size estimates from meta-analyses and multi-lab replication studies.\nFor the IDS preference effect, for example, we can thank the ManyBabies community for conducting both a multi-lab replication study and a community-augmented meta-analysis on infants’ preference to attend to IDS over ADS (ManyBabies Consortium, 2020; Zettersten, Cox, Bergmann, et al., 2023). By synthesising data across such a wide variety of experimental designs, participants and stimuli, we now have a fairly good estimate of the overall magnitude of the IDS preference effect. Both sources of evidence converge on an effect size of ~0.35 with 95% CI of [0.16; 0.47]. This section delves into the realm of effect sizes and teaches you how to implement a power analysis based on an effect size estimate.",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html#adapting-our-simulation-function-to-effect-size-data",
    "href": "content/SimulationBasedPowerAnalysis_02.html#adapting-our-simulation-function-to-effect-size-data",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "2 Adapting our Simulation Function to Effect Size Data",
    "text": "2 Adapting our Simulation Function to Effect Size Data\nLet’s continue with our IDS preference example and take inspiration from the ManyBabies1 estimate (https://doi.org/10.1177/2515245919900809) to think about how we would simulate data for a new experimental study on the IDS preference effect. Because our hypothetical study still revolves around a within-subjects, between-items study, we can rely on the simulation function from the previous page. All we have to do is to adapt the simulation function so that it suits the new scale of effect sizes.\nLet’s adapt our simulation function from previous pages to the new scale of effect sizes and call it SimulateEffectSizeData(). Following ManyBabies Consortium (2020), a positive effect size denotes longer looking times to IDS stimuli over ADS stimuli, and an effect size of 0 denotes no preference for either speech style (i.e., similar looking times to ADS and IDS stimuli).\n\n# set up the custom data simulation function\nSimulateEffectSizeData &lt;- function(\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 0,   # ADS intercept\n  mean_slope =  0.35,   # effect of IDS\n  item_varyingintercept =  0.1,   # by-item random intercept sd\n  subject_varyingintercept = 0.2,   # by-subject random intercept sd\n  subject_varyingslope =  0.2,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 1) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope),\n  r = rho, \n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\")\n) %&gt;%\n  mutate(subj_id = faux::make_id(nrow(.), \"S\"))\n\n   ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  ParameterValues %&gt;%\n    mutate(EF = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + e_si) %&gt;% #sum together overall intercept, varying subject and item intercepts, varying subject slopes, and random error.\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, EF)\n}\n\n\nEffectSizeDataSimulated &lt;- SimulateEffectSizeData()\nEffectSizeDataSimulated %&gt;%\n    ggplot() + geom_density(aes(EF, fill = Register), alpha = 0.8) +\n    geom_vline(xintercept = 0.35, linetype = 3) + geom_vline(xintercept = 0,\n    linetype = 3) + xlim(c(-4, 4)) + ggtitle(\"IDS Preference Effect in Effect Sizes\") +\n    xlab(\"Effect Size (d)\") + plot_theme + scale_fill_brewer(palette = \"Dark2\") +\n    theme(axis.title.y = element_blank(), axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n\n\nEffectSizeDataSimulated %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(EF), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Subject-Level Differences across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Effect Size (d)\") + plot_theme",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html#a-linear-mixed-effects-model-of-simulated-effect-size-data",
    "href": "content/SimulationBasedPowerAnalysis_02.html#a-linear-mixed-effects-model-of-simulated-effect-size-data",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "3 A Linear Mixed Effects Model of Simulated Effect Size Data",
    "text": "3 A Linear Mixed Effects Model of Simulated Effect Size Data\nLet’s think about how we want to run a linear mixed-effects model of the data. For a model with varying intercepts and varying slopes for subject and varying intercepts for item, an appropriate model could involve the following lmer syntax:\n\nEffectSizeDataSimulated &lt;- SimulateEffectSizeData()\n\nmodel &lt;- lmer(EF ~ 1 + SpeechStyle + (1 + SpeechStyle | subj_id) +\n    (1 | item_id), data = EffectSizeDataSimulated)\n\nsummary(model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ 1 + SpeechStyle + (1 + SpeechStyle | subj_id) + (1 | item_id)\n   Data: EffectSizeDataSimulated\n\nREML criterion at convergence: 832.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.8933 -0.6515  0.0122  0.6594  3.2162 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n subj_id  (Intercept) 0.01897  0.1377        \n          SpeechStyle 0.05202  0.2281   -0.07\n item_id  (Intercept) 0.04921  0.2218        \n Residual             0.97582  0.9878        \nNumber of obs: 288, groups:  subj_id, 24; item_id, 12\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)\n(Intercept) -0.03582    0.12557  9.89670  -0.285    0.781\nSpeechStyle  0.15985    0.17923 10.18933   0.892    0.393\n\nCorrelation of Fixed Effects:\n            (Intr)\nSpeechStyle -0.670\n\n\nIn the following code blocks, we will automatise this process and run the power analysis proper!",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html#time-to-power-up-the-analysis",
    "href": "content/SimulationBasedPowerAnalysis_02.html#time-to-power-up-the-analysis",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "4 Time to Power-Up the Analysis",
    "text": "4 Time to Power-Up the Analysis\nNow we have two essential components to perform our simulation-based power analysis: i) a code pipeline to generate data for our research question and ii) a clear idea of how we want to model the data. Now it’s time to run the actual power analysis. The way we do this is to specify an effect, run hundreds of models and calculate the proportion of models that reject the null hypothesis. This proportion is an estimate of statistical power for those particular parameter values.\nTo simplify the process, we can write a new function that combines a modelling component into our previous SimulateEffectSizeData() function. We will call this function SimulateAndModelEFData(), and we will use broom.mixed::tidy(model) to obtain a dataframe with relevant results from the model and write each model result to a .csv-file.\n\n# simulate, analyze, and return a table of parameter\n# estimates\nSimulateAndModelEFData &lt;- function(...) {\n    # simulate EF data function\n    dataSimulated &lt;- SimulateEffectSizeData()\n\n    # model EF data\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n    # write to a dataframee\n    broom.mixed::tidy(model)\n}",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html#running-the-power-analysis",
    "href": "content/SimulationBasedPowerAnalysis_02.html#running-the-power-analysis",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "5 Running the Power Analysis",
    "text": "5 Running the Power Analysis\nNow we have a function that generates data, runs a model and spits out the results! Now it’s time to repeat a few hundred times, so that we can calculate how much power we have with our given parameters. We are going to use map_df() to run the simulation and modelling function 500 times and write it to a .csv file.\n\n# run simulations and save to a file\nn_runs &lt;- 500  # use at least 500 to get stable estimates\nsimulations &lt;- purrr::map_df(1:n_runs, ~SimulateAndModelEFData())\nwrite_csv(simulations, here(\"EFsimulations.csv\"))\n\nIf it ran correctly, it should have produced a .csv file with model results from each new simulation of data. Let’s read in the results and have a look at what they say!\n\n# read saved simulation data\nsims &lt;- read_csv(here(\"EFsimulations.csv\"), show_col_types = FALSE) %&gt;%\n    dplyr::select(term, estimate, std.error, p.value)\n\nsims %&gt;%\n    group_by(term) %&gt;%\n    dplyr::summarize(mean_estimate = mean(estimate), mean_se = mean(std.error),\n        power = mean(p.value &lt; 0.05), .groups = \"drop\")\n\n# A tibble: 6 × 4\n  term                         mean_estimate mean_se  power\n  &lt;chr&gt;                                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercept)                        0.00199   0.106  0.052\n2 SpeechStyle                        0.351     0.148  0.594\n3 cor__(Intercept).SpeechStyle      NA        NA     NA    \n4 sd__(Intercept)                    0.134    NA     NA    \n5 sd__Observation                    0.991    NA     NA    \n6 sd__SpeechStyle                    0.270    NA     NA",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/SimulationBasedPowerAnalysis_02.html#exercises-to-check-understanding",
    "href": "content/SimulationBasedPowerAnalysis_02.html#exercises-to-check-understanding",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "6 Exercises to Check Understanding",
    "text": "6 Exercises to Check Understanding\n\n6.1 Exercise IV\nNow that we have this pipeline set up, it becomes easy to adapt the code to try out different parameter values. Let’s explore the effect of repeated measures on power. Try to run a power analysis with each subject receiving two items in each speech style. What happens to the estimate of statistical power?\n\n\nShow the code\n# simulate, analyze, and return a table of parameter\n# estimates\nSimulateAndModelEFData &lt;- function(...) {\n    # simulate EF data function\n    dataSimulated &lt;- SimulateEffectSizeData(n_ADS = 2, n_IDS = 2)\n\n    # model EF data\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n    # write to a dataframee\n    broom.mixed::tidy(model)\n}\n\n# run simulations and save to a file\nn_runs &lt;- 500  # use at least 500 to get stable estimates\nsimulations &lt;- purrr::map_df(1:n_runs, ~SimulateAndModelEFData())\nwrite_csv(simulations, here(\"EFsimulations2Stimuli.csv\"))\n\n\n\n\nShow the code\n# read saved simulation data\nsims &lt;- read_csv(here(\"EFsimulations2Stimuli.csv\"), show_col_types = FALSE) %&gt;%\n    dplyr::select(term, estimate, std.error, p.value)\n\nsims %&gt;%\n    group_by(term) %&gt;%\n    dplyr::summarize(mean_estimate = mean(estimate), mean_se = mean(std.error),\n        power = mean(p.value &lt; 0.05), .groups = \"drop\")\n\n\n# A tibble: 6 × 4\n  term                         mean_estimate mean_se  power\n  &lt;chr&gt;                                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercept)                         0.0144   0.184  0.04 \n2 SpeechStyle                         0.350    0.258  0.202\n3 cor__(Intercept).SpeechStyle       NA       NA     NA    \n4 sd__(Intercept)                     0.181   NA     NA    \n5 sd__Observation                     0.959   NA     NA    \n6 sd__SpeechStyle                     0.386   NA     NA    \n\n\n\n\n6.2 Exercise V\nLet’s imagine a scenario where we are interested in the effect of age on IDS preference. We would like to explore the extent to which we can detect a cross-sectional age effect given only two stimulus items per participant. How would adapt the above code to explore this experimental design?\n\n\nShow the code\nSimulateEFDataWithAge &lt;- function(\n  beta_age = 0.3, #add effect of age\n  age_interaction_sd = 0.1, #add some standard deviation to age effect\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 0,   # ADS intercept\n  mean_slope =  0.35,   # effect of IDS\n  item_varyingintercept =  0.1,   # by-item random intercept sd\n  subject_varyingintercept = 0.2,   # by-subject random intercept sd\n  subject_varyingslope =  0.2,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 1) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope, age_interaction_sd), \n  r = rho,\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\", \"age_slope_sd\")\n) %&gt;%\n    mutate(subj_id = faux::make_id(nrow(.), \"S\")) %&gt;%\n    mutate(age_subj = runif(n_subj, min = -0.5, max = 0.5))\n\n  ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  ParameterValues %&gt;%\n    mutate(EF = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + ((beta_age + age_slope_sd) * age_subj * SpeechStyle) + e_si) %&gt;%\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, age_subj, EF)\n}\n\n\n\n\nShow the code\nDataWithAgeSimulated &lt;- SimulateEFDataWithAge()\nDataWithAgeSimulated %&gt;%\n    ggplot() + geom_point(aes(y = EF, x = age_subj, color = subj_id),\n    alpha = 0.6, size = 1, show.legend = F) + geom_smooth(method = \"lm\",\n    se = TRUE, formula = y ~ x, aes(y = EF, x = age_subj)) +\n    ggtitle(\"Interaction Effect with Age\") + xlab(\"Age (standardised age)\") +\n    facet_wrap(~Register) + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# simulate, analyze, and return a table of parameter\n# estimates\nSimulateAndModelEFAgeData &lt;- function(...) {\n    # simulate EF data function\n    dataSimulated &lt;- SimulateEFDataWithAge(n_ADS = 4, n_IDS = 4)\n\n    # model EF data\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + SpeechStyle:age_subj +\n        (1 | item_id) + (1 + SpeechStyle | subj_id), data = dataSimulated)\n    # write to a dataframee\n    broom.mixed::tidy(model)\n}\n\n# run simulations and save to a file\nn_runs &lt;- 500  # use at least 500 to get stable estimates\nsimulations &lt;- purrr::map_df(1:n_runs, ~SimulateAndModelEFAgeData())\nwrite_csv(simulations, here(\"EFsimulationsAge.csv\"))\n\n\n\n\nShow the code\n# read saved simulation data\nsims &lt;- read_csv(here(\"EFsimulationsAge.csv\"), show_col_types = FALSE) %&gt;%\n    dplyr::select(term, estimate, std.error, p.value)\n\nsims %&gt;%\n    group_by(term) %&gt;%\n    dplyr::summarize(mean_estimate = mean(estimate), mean_se = mean(std.error),\n        power = mean(p.value &lt; 0.05), .groups = \"drop\")\n\n\n# A tibble: 7 × 4\n  term                         mean_estimate mean_se  power\n  &lt;chr&gt;                                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercept)                        0.00200   0.130  0.044\n2 SpeechStyle                        0.347     0.188  0.356\n3 SpeechStyle:age_subj               0.286     0.435  0.094\n4 cor__(Intercept).SpeechStyle      NA        NA     NA    \n5 sd__(Intercept)                    0.141    NA     NA    \n6 sd__Observation                    0.989    NA     NA    \n7 sd__SpeechStyle                    0.313    NA     NA    \n\n\nNow we have a pretty useful pipeline set up that allows us to explore the effects of different parameter values on our ability to detect effects. However, instead of manually varying the parameters one by one, it would be nice if we could set up a grid search to explore values and put the power results into perspective. We will explore how to do this in the next exercise sheet. The code gets slightly more complex, so make sure that you have understood the code that we have written so far before venturing further.",
    "crumbs": [
      "Part II, Simulation-Based Power Analysis"
    ]
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html",
    "href": "content/02_SimulationBasedPowerAnalysis.html",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "",
    "text": "Up until now, we have relied solely on our intuitions about infant looking times based on our experience with conducting infant experiments. This strategy introduces lots of assumptions into the simulation process and creates a multiverse of different parameter settings that have real effects on power analyses. In this section, we consider how to improve our data simulation process by capitalising on cumulative science efforts, such as using effect size estimates from meta-analyses and multi-lab replication studies.\nFor the IDS preference effect, for example, we can thank the ManyBabies community for conducting both a multi-lab replication study and a community-augmented meta-analysis on infants’ preference to attend to IDS over ADS (ManyBabies Consortium, 2020; Zettersten, Cox, Bergmann, et al., 2023). By synthesising data across such a wide variety of experimental designs, participants and stimuli, we now have a fairly good estimate of the overall magnitude of the IDS preference effect. Both sources of evidence converge on an effect size of ~0.35 with 95% CI of [0.16; 0.47]. This section delves into the realm of effect sizes and teaches you how to implement a power analysis based on an effect size estimate."
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html#cumulative-science-and-prior-knowledge",
    "href": "content/02_SimulationBasedPowerAnalysis.html#cumulative-science-and-prior-knowledge",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "",
    "text": "Up until now, we have relied solely on our intuitions about infant looking times based on our experience with conducting infant experiments. This strategy introduces lots of assumptions into the simulation process and creates a multiverse of different parameter settings that have real effects on power analyses. In this section, we consider how to improve our data simulation process by capitalising on cumulative science efforts, such as using effect size estimates from meta-analyses and multi-lab replication studies.\nFor the IDS preference effect, for example, we can thank the ManyBabies community for conducting both a multi-lab replication study and a community-augmented meta-analysis on infants’ preference to attend to IDS over ADS (ManyBabies Consortium, 2020; Zettersten, Cox, Bergmann, et al., 2023). By synthesising data across such a wide variety of experimental designs, participants and stimuli, we now have a fairly good estimate of the overall magnitude of the IDS preference effect. Both sources of evidence converge on an effect size of ~0.35 with 95% CI of [0.16; 0.47]. This section delves into the realm of effect sizes and teaches you how to implement a power analysis based on an effect size estimate."
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html#adapting-our-simulation-function-to-effect-size-data",
    "href": "content/02_SimulationBasedPowerAnalysis.html#adapting-our-simulation-function-to-effect-size-data",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "2 Adapting our Simulation Function to Effect Size Data",
    "text": "2 Adapting our Simulation Function to Effect Size Data\nLet’s continue with our IDS preference example and take inspiration from the ManyBabies1 estimate (https://doi.org/10.1177/2515245919900809) to think about how we would simulate data for a new experimental study on the IDS preference effect. Because our hypothetical study still revolves around a within-subjects, between-items study, we can rely on the simulation function from the previous page. All we have to do is to adapt the simulation function so that it suits the new scale of effect sizes.\nLet’s adapt our simulation function from previous pages to the new scale of effect sizes and call it SimulateEffectSizeData(). Following ManyBabies Consortium (2020), a positive effect size denotes longer looking times to IDS stimuli over ADS stimuli, and an effect size of 0 denotes no preference for either speech style (i.e., similar looking times to ADS and IDS stimuli).\n\n# set up the custom data simulation function\nSimulateEffectSizeData &lt;- function(\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 0,   # ADS intercept\n  mean_slope =  0.35,   # effect of IDS\n  item_varyingintercept =  0.1,   # by-item random intercept sd\n  subject_varyingintercept = 0.2,   # by-subject random intercept sd\n  subject_varyingslope =  0.2,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 1) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope),\n  r = rho, \n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\")\n) %&gt;%\n  mutate(subj_id = faux::make_id(nrow(.), \"S\"))\n\n   ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  ParameterValues %&gt;%\n    mutate(EF = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + e_si) %&gt;% #sum together overall intercept, varying subject and item intercepts, varying subject slopes, and random error.\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, EF)\n}\n\n\nEffectSizeDataSimulated &lt;- SimulateEffectSizeData()\nEffectSizeDataSimulated %&gt;%\n    ggplot() + geom_density(aes(EF, fill = Register), alpha = 0.8) +\n    geom_vline(xintercept = 0.35, linetype = 3) + geom_vline(xintercept = 0,\n    linetype = 3) + xlim(c(-4, 4)) + ggtitle(\"IDS Preference Effect in Effect Sizes\") +\n    xlab(\"Effect Size (d)\") + plot_theme + scale_fill_brewer(palette = \"Dark2\") +\n    theme(axis.title.y = element_blank(), axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n\n\nEffectSizeDataSimulated %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(EF), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Subject-Level Differences across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Effect Size (d)\") + plot_theme"
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html#a-linear-mixed-effects-model-of-simulated-effect-size-data",
    "href": "content/02_SimulationBasedPowerAnalysis.html#a-linear-mixed-effects-model-of-simulated-effect-size-data",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "3 A Linear Mixed Effects Model of Simulated Effect Size Data",
    "text": "3 A Linear Mixed Effects Model of Simulated Effect Size Data\nLet’s think about how we want to run a linear mixed-effects model of the data. For a model with varying intercepts and varying slopes for subject and varying intercepts for item, an appropriate model could involve the following lmer syntax:\n\nEffectSizeDataSimulated &lt;- SimulateEffectSizeData()\n\nmodel &lt;- lmer(EF ~ 1 + SpeechStyle + (1 + SpeechStyle | subj_id) +\n    (1 | item_id), data = EffectSizeDataSimulated)\n\nsummary(model)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: EF ~ 1 + SpeechStyle + (1 + SpeechStyle | subj_id) + (1 | item_id)\n   Data: EffectSizeDataSimulated\n\nREML criterion at convergence: 832.8\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.8933 -0.6515  0.0122  0.6594  3.2162 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n subj_id  (Intercept) 0.01897  0.1377        \n          SpeechStyle 0.05202  0.2281   -0.07\n item_id  (Intercept) 0.04921  0.2218        \n Residual             0.97582  0.9878        \nNumber of obs: 288, groups:  subj_id, 24; item_id, 12\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)\n(Intercept) -0.03582    0.12557  9.89670  -0.285    0.781\nSpeechStyle  0.15985    0.17923 10.18933   0.892    0.393\n\nCorrelation of Fixed Effects:\n            (Intr)\nSpeechStyle -0.670\n\n\nIn the following code blocks, we will automatise this process and run the power analysis proper!"
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html#time-to-power-up-the-analysis",
    "href": "content/02_SimulationBasedPowerAnalysis.html#time-to-power-up-the-analysis",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "4 Time to Power-Up the Analysis",
    "text": "4 Time to Power-Up the Analysis\nNow we have two essential components to perform our simulation-based power analysis: i) a code pipeline to generate data for our research question and ii) a clear idea of how we want to model the data. Now it’s time to run the actual power analysis. The way we do this is to specify an effect, run hundreds of models and calculate the proportion of models that reject the null hypothesis. This proportion is an estimate of statistical power for those particular parameter values.\nTo simplify the process, we can write a new function that combines a modelling component into our previous SimulateEffectSizeData() function. We will call this function SimulateAndModelEFData(), and we will use broom.mixed::tidy(model) to obtain a dataframe with relevant results from the model and write each model result to a .csv-file.\n\n# simulate, analyze, and return a table of parameter\n# estimates\nSimulateAndModelEFData &lt;- function(...) {\n    # simulate EF data function\n    dataSimulated &lt;- SimulateEffectSizeData()\n\n    # model EF data\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n    # write to a dataframee\n    broom.mixed::tidy(model)\n}"
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html#running-the-power-analysis",
    "href": "content/02_SimulationBasedPowerAnalysis.html#running-the-power-analysis",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "5 Running the Power Analysis",
    "text": "5 Running the Power Analysis\nNow we have a function that generates data, runs a model and spits out the results! Now it’s time to repeat a few hundred times, so that we can calculate how much power we have with our given parameters. We are going to use map_df() to run the simulation and modelling function 500 times and write it to a .csv file.\n\n# run simulations and save to a file\nn_runs &lt;- 500  # use at least 500 to get stable estimates\nsimulations &lt;- purrr::map_df(1:n_runs, ~SimulateAndModelEFData())\nwrite_csv(simulations, here(\"EFsimulations.csv\"))\n\nIf it ran correctly, it should have produced a .csv file with model results from each new simulation of data. Let’s read in the results and have a look at what they say!\n\n# read saved simulation data\nsims &lt;- read_csv(here(\"EFsimulations.csv\"), show_col_types = FALSE) %&gt;%\n    dplyr::select(term, estimate, std.error, p.value)\n\nsims %&gt;%\n    group_by(term) %&gt;%\n    dplyr::summarize(mean_estimate = mean(estimate), mean_se = mean(std.error),\n        power = mean(p.value &lt; 0.05), .groups = \"drop\")\n\n# A tibble: 6 × 4\n  term                         mean_estimate mean_se  power\n  &lt;chr&gt;                                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercept)                        0.00199   0.106  0.052\n2 SpeechStyle                        0.351     0.148  0.594\n3 cor__(Intercept).SpeechStyle      NA        NA     NA    \n4 sd__(Intercept)                    0.134    NA     NA    \n5 sd__Observation                    0.991    NA     NA    \n6 sd__SpeechStyle                    0.270    NA     NA"
  },
  {
    "objectID": "content/02_SimulationBasedPowerAnalysis.html#exercises-to-check-understanding",
    "href": "content/02_SimulationBasedPowerAnalysis.html#exercises-to-check-understanding",
    "title": "Part II, Simulation-Based Power Analysis",
    "section": "6 Exercises to Check Understanding",
    "text": "6 Exercises to Check Understanding\n\n6.1 Exercise IV\nNow that we have this pipeline set up, it becomes easy to adapt the code to try out different parameter values. Let’s explore the effect of repeated measures on power. Try to run a power analysis with each subject receiving two items in each speech style. What happens to the estimate of statistical power?\n\n\nShow the code\n# simulate, analyze, and return a table of parameter\n# estimates\nSimulateAndModelEFData &lt;- function(...) {\n    # simulate EF data function\n    dataSimulated &lt;- SimulateEffectSizeData(n_ADS = 2, n_IDS = 2)\n\n    # model EF data\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n    # write to a dataframee\n    broom.mixed::tidy(model)\n}\n\n# run simulations and save to a file\nn_runs &lt;- 500  # use at least 500 to get stable estimates\nsimulations &lt;- purrr::map_df(1:n_runs, ~SimulateAndModelEFData())\nwrite_csv(simulations, here(\"EFsimulations2Stimuli.csv\"))\n\n\n\n\nShow the code\n# read saved simulation data\nsims &lt;- read_csv(here(\"EFsimulations2Stimuli.csv\"), show_col_types = FALSE) %&gt;%\n    dplyr::select(term, estimate, std.error, p.value)\n\nsims %&gt;%\n    group_by(term) %&gt;%\n    dplyr::summarize(mean_estimate = mean(estimate), mean_se = mean(std.error),\n        power = mean(p.value &lt; 0.05), .groups = \"drop\")\n\n\n# A tibble: 6 × 4\n  term                         mean_estimate mean_se  power\n  &lt;chr&gt;                                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercept)                         0.0144   0.184  0.04 \n2 SpeechStyle                         0.350    0.258  0.202\n3 cor__(Intercept).SpeechStyle       NA       NA     NA    \n4 sd__(Intercept)                     0.181   NA     NA    \n5 sd__Observation                     0.959   NA     NA    \n6 sd__SpeechStyle                     0.386   NA     NA    \n\n\n\n\n6.2 Exercise V\nLet’s imagine a scenario where we are interested in the effect of age on IDS preference. We would like to explore the extent to which we can detect a cross-sectional age effect given only two stimulus items per participant. How would adapt the above code to explore this experimental design?\n\n\nShow the code\nSimulateEFDataWithAge &lt;- function(\n  beta_age = 0.3, #add effect of age\n  age_interaction_sd = 0.1, #add some standard deviation to age effect\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 0,   # ADS intercept\n  mean_slope =  0.35,   # effect of IDS\n  item_varyingintercept =  0.1,   # by-item random intercept sd\n  subject_varyingintercept = 0.2,   # by-subject random intercept sd\n  subject_varyingslope =  0.2,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 1) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope, age_interaction_sd), \n  r = rho,\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\", \"age_slope_sd\")\n) %&gt;%\n    mutate(subj_id = faux::make_id(nrow(.), \"S\")) %&gt;%\n    mutate(age_subj = runif(n_subj, min = -0.5, max = 0.5))\n\n  ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  ParameterValues %&gt;%\n    mutate(EF = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + ((beta_age + age_slope_sd) * age_subj * SpeechStyle) + e_si) %&gt;%\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, age_subj, EF)\n}\n\n\n\n\nShow the code\nDataWithAgeSimulated &lt;- SimulateEFDataWithAge()\nDataWithAgeSimulated %&gt;%\n    ggplot() + geom_point(aes(y = EF, x = age_subj, color = subj_id),\n    alpha = 0.6, size = 1, show.legend = F) + geom_smooth(method = \"lm\",\n    se = TRUE, formula = y ~ x, aes(y = EF, x = age_subj)) +\n    ggtitle(\"Interaction Effect with Age\") + xlab(\"Age (standardised age)\") +\n    facet_wrap(~Register) + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# simulate, analyze, and return a table of parameter\n# estimates\nSimulateAndModelEFAgeData &lt;- function(...) {\n    # simulate EF data function\n    dataSimulated &lt;- SimulateEFDataWithAge(n_ADS = 4, n_IDS = 4)\n\n    # model EF data\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + SpeechStyle:age_subj +\n        (1 | item_id) + (1 + SpeechStyle | subj_id), data = dataSimulated)\n    # write to a dataframee\n    broom.mixed::tidy(model)\n}\n\n# run simulations and save to a file\nn_runs &lt;- 500  # use at least 500 to get stable estimates\nsimulations &lt;- purrr::map_df(1:n_runs, ~SimulateAndModelEFAgeData())\nwrite_csv(simulations, here(\"EFsimulationsAge.csv\"))\n\n\n\n\nShow the code\n# read saved simulation data\nsims &lt;- read_csv(here(\"EFsimulationsAge.csv\"), show_col_types = FALSE) %&gt;%\n    dplyr::select(term, estimate, std.error, p.value)\n\nsims %&gt;%\n    group_by(term) %&gt;%\n    dplyr::summarize(mean_estimate = mean(estimate), mean_se = mean(std.error),\n        power = mean(p.value &lt; 0.05), .groups = \"drop\")\n\n\n# A tibble: 7 × 4\n  term                         mean_estimate mean_se  power\n  &lt;chr&gt;                                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 (Intercept)                        0.00200   0.130  0.044\n2 SpeechStyle                        0.347     0.188  0.356\n3 SpeechStyle:age_subj               0.286     0.435  0.094\n4 cor__(Intercept).SpeechStyle      NA        NA     NA    \n5 sd__(Intercept)                    0.141    NA     NA    \n6 sd__Observation                    0.989    NA     NA    \n7 sd__SpeechStyle                    0.313    NA     NA    \n\n\nNow we have a pretty useful pipeline set up that allows us to explore the effects of different parameter values on our ability to detect effects. However, instead of manually varying the parameters one by one, it would be nice if we could set up a grid search to explore values and put the power results into perspective. We will explore how to do this in the next exercise sheet. The code gets slightly more complex, so make sure that you have understood the code that we have written so far before venturing further."
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html",
    "href": "content/01_ExerciseDataSimulation.html",
    "title": "Part I, Data Simulation",
    "section": "",
    "text": "In this first task, we will deal with a dependent variable that should be familiar to many researchers within developmental science: infant looking times. In our hypothetical study (modelled on ManyBabies1), infant participants are exposed to recordings of adult-directed speech (ADS) and infant-directed speech (IDS), and infants’ looking times to an unrelated visual stimulus is recorded as the primary dependent variable. The key question is whether there are any behavioural differences according to the set of stimuli (i.e., ADS vs. IDS) within each participant. To gain familiarity with the simulation process and to build up the structure for a simulation function that will help us when performing the power analysis in Part II, we will simulate data on the scale of looking times (i.e., 0-20,000ms). In the next section, we will extend this process to simulate effect size data."
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#a-description-of-the-example-and-aim-of-the-simulation",
    "href": "content/01_ExerciseDataSimulation.html#a-description-of-the-example-and-aim-of-the-simulation",
    "title": "Part I, Data Simulation",
    "section": "",
    "text": "In this first task, we will deal with a dependent variable that should be familiar to many researchers within developmental science: infant looking times. In our hypothetical study (modelled on ManyBabies1), infant participants are exposed to recordings of adult-directed speech (ADS) and infant-directed speech (IDS), and infants’ looking times to an unrelated visual stimulus is recorded as the primary dependent variable. The key question is whether there are any behavioural differences according to the set of stimuli (i.e., ADS vs. IDS) within each participant. To gain familiarity with the simulation process and to build up the structure for a simulation function that will help us when performing the power analysis in Part II, we will simulate data on the scale of looking times (i.e., 0-20,000ms). In the next section, we will extend this process to simulate effect size data."
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#determining-the-experimental-parameters",
    "href": "content/01_ExerciseDataSimulation.html#determining-the-experimental-parameters",
    "title": "Part I, Data Simulation",
    "section": "2 Determining the Experimental Parameters",
    "text": "2 Determining the Experimental Parameters\nBefore we can start to simulate data, we need to be very clear about the study design. This clarity is important because we need to explicitly define the parameters that we assume govern the process of data generation. If we are designing a similar study to that of ManyBabies1, then we are dealing with a within-subjects, between-items study; that is, each and every subject receives both ADS and IDS stimuli (within-subject), but each stimulus is either ADS or IDS (between-items).\nBecause infants are not the most patient of participants, perhaps a realistic study design would allow researchers to expose infants to 6 recordings of ADS and 6 recordings of IDS. And let’s say that a realistic sample size in our imaginary laboratory would be around 25 participants. This would imply a total of 300 observations in this study (i.e., 6 + 6 recording stimuli for each of the 25 children). Let’s set start by setting these experimental parameters.\n\n# set number of subjects and items\nn_subj &lt;- 25 # number of infant participants\nn_ADS  &lt;-  6 # number of ADS stimuli\nn_IDS  &lt;-  6 # number of IDS stimuli"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#data-generating-parameters",
    "href": "content/01_ExerciseDataSimulation.html#data-generating-parameters",
    "title": "Part I, Data Simulation",
    "section": "3 Data Generating Parameters",
    "text": "3 Data Generating Parameters\nNow that we have an overview of the experimental design, we can start to consider a reasonable underlying statistical model. In the following sections, we will gradually build up the parameters for a linear mixed-effects model of the following type, as described in the lecture:\n\\[\nLooking Time = \\beta^{ADS} + VaryingIntercept^{subj} + VaryingIntercept^{item} + (\\beta^{IDS} + VaryingSlope^{subj}) \\cdot SpeechStyle + \\varepsilon\n\\] According to this formula, the process of data generation means that our dependent variable of looking time is composed of a linear combination of the following fixed parameters:\n\nthe average ADS intercept capturing the mean baseline tendency to attend to ADS, β(ADS)\nthe average influence of IDS on this baseline attention, β(IDS)\n\nThere are also three varying effects:\n\na by-subject random intercept, VaryingIntercept(subj),\na by-item random intercept, VaryingIntercept(item)\na by-subject random slope, VaryingSlope(subj)\n\nAnd lastly:\n\na trial-level residual error, ε\n\nThis formula paves a clear way forward for our process of data simulation. In the next section, we will build up a statistical model step by step, defining variables in the code as we go along that reflect our choices for the different parameters."
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#choosing-values-for-fixed-effect-parameters",
    "href": "content/01_ExerciseDataSimulation.html#choosing-values-for-fixed-effect-parameters",
    "title": "Part I, Data Simulation",
    "section": "4 Choosing Values for Fixed Effect Parameters",
    "text": "4 Choosing Values for Fixed Effect Parameters\nLet’s start by setting the fixed-effect parameters of SpeechStyle (β₀ + β₁*SpeechStyle). How should we set these parameters? A good place to start would be to be guided by what we know about looking time distributions in infant experiments. For example, we could imagine average infant looking times to be around 6 seconds (i.e., 6000ms) and for IDS stimuli to increase infant looking time by 1 second (i.e., 1000ms). Let’s go ahead and set these values as parameters in our simulation.\n\n# set fixed effect parameters\nmean_intercept &lt;- 6000  # ADS intercept; i.e., the grand mean, β₀\nmean_slope &lt;- 1000  # slope; i.e, effect of IDS, β₁"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#choosing-values-for-varying-intercept-parameters",
    "href": "content/01_ExerciseDataSimulation.html#choosing-values-for-varying-intercept-parameters",
    "title": "Part I, Data Simulation",
    "section": "5 Choosing Values for Varying Intercept Parameters",
    "text": "5 Choosing Values for Varying Intercept Parameters\nWhen we’re modelling data from experiments involving individuals (like infants in this case), it’s essential to account for the fact that each individual may have unique baseline reactions to the speech stimuli. Similarly, the effect of the stimuli on infant looking times might vary across different instances of the stimulus items.\nTo address this, we introduce random intercept values for subjects and items by coding the standard deviation of the random intercepts and sampling from a normal distribution. This reflects the range of differences we might observe among subjects’ reactions and the effects of different stimulus items.\n\n# set random effect parameters\nsubject_varyingintercept &lt;- 500  # by-subject random intercept sd\nitem_varyingintercept &lt;- 250  # by-item random intercept sd"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#choosing-value-for-varying-slope-parameter",
    "href": "content/01_ExerciseDataSimulation.html#choosing-value-for-varying-slope-parameter",
    "title": "Part I, Data Simulation",
    "section": "6 Choosing Value for Varying Slope Parameter",
    "text": "6 Choosing Value for Varying Slope Parameter\nWe also need to acknowledge that the magnitude of the effect of IDS stimuli may vary across individual infants. Some infants might be more responsive to IDS stimuli than others, leading to variation in the differences in looking times across speech styles. We therefore introduce a slope parameter that varies by subject. When we introduce random slopes to a model, we need to consider potential correlations between these varying slopes and the varying intercepts. This is because if there is a correlation between the way individuals (infants, in this case) respond to the IDS stimuli (reflected in the varying slopes) and their baseline behaviors (reflected in the varying intercepts), it can affect our model’s predictions. For instance, if infants who naturally have longer attention spans (reflected in higher random intercepts) also tend to show stronger responses to IDS stimuli (reflected in steeper random slopes), ignoring this correlation might lead to biased estimates. Including a correlation matrix allows us to explicitly account for these potential correlations, ensuring that our model accurately captures the relationships between different sources of variability in the data and produces more reliable results. Hence, in the following code, we include a correlation matrix, specifying a weak correlation between the varying intercepts and varying slopes of infant participants. Lastly, we incorporate a residual error term to account for any unexplained sources of variability in the model.\n\n# set more random effect and error parameters\nsubject_varyingslope &lt;- 300  # by-subject random slope sd\nrho &lt;- 0.2  # correlation between intercept and slope\nsigma &lt;- 500  # residual (error) sd"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#simulate-stimulus-items",
    "href": "content/01_ExerciseDataSimulation.html#simulate-stimulus-items",
    "title": "Part I, Data Simulation",
    "section": "7 Simulate Stimulus Items",
    "text": "7 Simulate Stimulus Items\nNow it’s time to create a dataset that lists, for each stimulus item, the speech style it is in and its varying properties on infants’ looking times. To set the parameter for varying item intercept, we are going to specify the standard deviation that we expect items to exhibit in the parameter, item_varyingintercept, in the below code. That is, we sample values from a normal distribution using the rnorm() function, with a mean of 0 and standard deviation of item_varyingintercept. For the varying item variable, we also need to assign a unique identifer to each of the 16 speech stimuli and designate whether the stimuli are ADS or IDS, with the first 8 being ADS and the next 8 being IDS. We are going to use the faux package to carry this out.\n\n# simulate a sample of items\n# total number of items = n_ADS + n_IDS\nitems &lt;- data.frame(\n  Register = rep(c(\"ADS\", \"IDS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% #add so that we have numeric predictors\n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\nTo get to better grips with the simulation process, let’s visualise the data and take a look:\n\nglimpse(items)\n\nRows: 12\nColumns: 4\n$ Register          &lt;chr&gt; \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"IDS\", \"ID…\n$ item_intercept_sd &lt;dbl&gt; -301.76644, 69.35731, 271.11029, -586.42443, 107.281…\n$ SpeechStyle       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1\n$ item_id           &lt;chr&gt; \"I01\", \"I02\", \"I03\", \"I04\", \"I05\", \"I06\", \"I07\", \"I0…\n\nggplot(items, aes(1, item_intercept_sd, fill = Register, color = Register)) +\n    geom_rain(alpha = 0.8, boxplot.args = list(color = \"black\",\n        outlier.shape = NA)) + ggtitle(\"Varying Intercept Terms for Stimulus Item\") +\n    ylab(\"SD of Item Intercept (ms)\") + facet_wrap(~Register) +\n    scale_fill_brewer(palette = \"Dark2\") + scale_color_brewer(palette = \"Dark2\") +\n    plot_theme + theme(axis.title.x = element_blank(), axis.text.x = element_blank(),\n    axis.ticks.x = element_blank())"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#simulate-the-sampling-of-subjects",
    "href": "content/01_ExerciseDataSimulation.html#simulate-the-sampling-of-subjects",
    "title": "Part I, Data Simulation",
    "section": "8 Simulate the sampling of subjects",
    "text": "8 Simulate the sampling of subjects\nThe process of simulating varying intercepts varying slopes data for subjects is slightly more complex than that of items. This process is slightly more complex than before because we cannot simply sample the intercept values independently from the slope values using rnorm(). Instead, we need to sample pairs of values for each subject from a bivariate normal distribution because we need to account for patterns in the data among those infants who have a high looking time baseline in ADS and the effects of IDS. We will use the rnorm_multi() function from the faux package (DeBruine 2020) to carry this out. This function allows us to specify the means, and standard deviations (sd) for each variable, along with the correlations (rho), which in this case will be a single value applied to all pairs.\n\n# simulate a sample of subjects\n# sample from a multivariate random distribution \nsubjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, # means for random effects are always 0\n  sd = c(subject_varyingintercept, subject_varyingslope), # note that we set the SDs further up in the code when specifying varying intercepts and sloeps.\n  r = rho, # set correlation, see ?faux::rnorm_multi\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\")\n) %&gt;%\n  mutate(subj_id = faux::make_id(nrow(.), \"S\")) # add subject ids that correspond to the number of rows simulated.\n\nAgain, let’s visualise this process, so that we are sure what the code is doing.\n\nglimpse(subjects)\n\nRows: 25\nColumns: 3\n$ subject_intercept_sd &lt;dbl&gt; 316.45486, -47.32471, -501.32994, 130.05144, 198.…\n$ subject_slope_sd     &lt;dbl&gt; 453.69360, 78.39230, 46.78022, -404.79294, 351.84…\n$ subj_id              &lt;chr&gt; \"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", …\n\nsubjects %&gt;%\n    pivot_longer(cols = starts_with(\"subject\"), names_to = \"Parameters\",\n        values_to = \"value\") %&gt;%\n    ggplot() + geom_density(aes(value, fill = Parameters), alpha = 0.8) +\n    xlim(c(-4 * subject_varyingintercept, 4 * subject_varyingintercept)) +\n    facet_wrap(~Parameters) + ggtitle(\"Varying Intercept and Slope Terms for Subjects\") +\n    xlab(\"Looking Times (ms)\") + plot_theme + scale_fill_brewer(palette = \"Dark2\") +\n    theme(axis.title.y = element_blank(), axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#time-to-put-it-all-together",
    "href": "content/01_ExerciseDataSimulation.html#time-to-put-it-all-together",
    "title": "Part I, Data Simulation",
    "section": "9 Time to Put It All Together",
    "text": "9 Time to Put It All Together\nBecause all subjects respond to all stimulus items, we can create a dataset with every possible combination of the rows in the simulated subject and item datasets. For this we use the tidyverse function crossing(). To introduce inherent fluctuations in trial-by-trial performance, we also incorporate random error into each trial at this stage, based on our sigma value (specified above). The output of this approach means that our dataset captures the full range of subject-item interactions while accounting for unpredictable variations in individual performance across trials.\n\n# cross subject and item IDs; add an error term\nParameterValues &lt;- crossing(subjects, items) %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n\nglimpse(ParameterValues)\n\nRows: 300\nColumns: 8\n$ subject_intercept_sd &lt;dbl&gt; -1252.9874, -1252.9874, -1252.9874, -1252.9874, -…\n$ subject_slope_sd     &lt;dbl&gt; 66.65159, 66.65159, 66.65159, 66.65159, 66.65159,…\n$ subj_id              &lt;chr&gt; \"S08\", \"S08\", \"S08\", \"S08\", \"S08\", \"S08\", \"S08\", …\n$ Register             &lt;chr&gt; \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"IDS\", …\n$ item_intercept_sd    &lt;dbl&gt; -586.42443, -301.76644, 69.35731, 107.28117, 126.…\n$ SpeechStyle          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0…\n$ item_id              &lt;chr&gt; \"I04\", \"I01\", \"I02\", \"I05\", \"I06\", \"I03\", \"I12\", …\n$ e_si                 &lt;dbl&gt; -17.380195, -334.816790, -3.802378, 888.542224, -…\n\n\nNow we have specified the parameters in ParameterValues, we are ready to add up everything together to create the response variable (i.e., infant looking times in milliseconds).\n\n# calculate the response variable\nSimulatedLT &lt;- ParameterValues %&gt;%\n  mutate(LT = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + e_si) %&gt;% #sum together overall intercept, varying subject and item intercepts, varying subject slopes, and random error.\n  mutate(LT = LT + rexp(nrow(.), rate = 0.01)) %&gt;% #add a long tail to the distribution to simulate exgaussian distribution of looking times\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, LT)\n\nLet’s have a look at what the data we have generated looks like:\n\n# Plot of how overall looking time distributions differ\n# across ADS and IDS\nSimulatedLT %&gt;%\n    ggplot() + geom_density(aes(LT, fill = Register), alpha = 0.8) +\n    xlim(c(2400, 15000)) + ggtitle(\"Simulated Distributions for ADS and IDS\") +\n    plot_theme + scale_fill_brewer(palette = \"Dark2\") + theme(axis.title.y = element_blank(),\n    axis.text.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n# Plot of how looking times of indvidual subjects differ\n# across the two speech style\nSimulatedLT %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(LT), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Individual Subject Looking Times across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Looking Time (ms)\") + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#with-the-initial-setup-done-lets-automatise-with-a-function",
    "href": "content/01_ExerciseDataSimulation.html#with-the-initial-setup-done-lets-automatise-with-a-function",
    "title": "Part I, Data Simulation",
    "section": "10 With the Initial Setup Done, Let’s Automatise with a Function!",
    "text": "10 With the Initial Setup Done, Let’s Automatise with a Function!\nNow that we’ve simulated a dataset with the necessary properties, suitable for sophisticated linear mixed effects models, we can streamline the process by encapsulating all the preceding code into a custom function. This function will accept the parameters we defined earlier as arguments, with default values set to our chosen parameters.\n\n# set up the custom data simulation function\nSimulateLTData &lt;- function(\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 6000,   # ADS intercept\n  mean_slope =  1000,   # effect of IDS\n  item_varyingintercept =  250,   # by-item random intercept sd\n  subject_varyingintercept = 500,   # by-subject random intercept sd\n  subject_varyingslope =  300,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 500) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope), \n  r = rho,\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\")\n) %&gt;%\n  mutate(subj_id = faux::make_id(nrow(.), \"S\"))\n\n  ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  # calculate the response variable\n  ParameterValues %&gt;%\n    mutate(LT = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + e_si) %&gt;% #sum together overall intercept, varying subject and item intercepts, varying subject slopes, and random error.\n  mutate(LT = LT + rexp(nrow(.), rate = 0.01)) %&gt;% #add a long tail to the distribution to simulate exgaussian distribution of looking times\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, LT)\n}\n\nHaving condense all the preceding steps into a single function and returning a dataset with the specified parameters, we are now empowered to effortlessly experiment with different parameters or generate multiple datasets for power analysis purposes.\nFor example, we can easily generate a dataset with the effect of IDS being 3000ms instead of only 1000ms by specifying the following\n\nSimulatedDataWithIDSslopeOf3000 &lt;- SimulateLTData(mean_slope = 3000)\n\n# Plot of how looking times of indvidual subjects differ\n# across the two speech style\nSimulatedDataWithIDSslopeOf3000 %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(LT), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Individual Subject Looking Times across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Looking Time (ms)\") + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme\n\nWarning: Duplicated aesthetics after name standardisation: alpha"
  },
  {
    "objectID": "content/01_ExerciseDataSimulation.html#exercises-to-check-understanding",
    "href": "content/01_ExerciseDataSimulation.html#exercises-to-check-understanding",
    "title": "Part I, Data Simulation",
    "section": "11 Exercises to Check Understanding",
    "text": "11 Exercises to Check Understanding\n\n11.1 Exercise I\n\nHow would you adapt the above code to generate a dataset with 500 participants and no effect of SpeechStyle (i.e., distributions similar to the below plot)? Try to get inspiration from the below plot, code up a solution, and only then click on “Show the code” to check how you might approach this.\n\n\n\nShow the code\n# With our new SimulateLTData() function, the answer here\n# is fairly straightforward! We can simply specify that we\n# want to simulate 500 subjects and want a mean slope of 0,\n# like so:\n\nLTDataSimulated &lt;- SimulateLTData(n_subj = 500, mean_slope = 0)\n\nLTDataSimulated %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(LT), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Looking Time Differences across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Looking Time (ms)\") + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme\n\n\n\n\n\n\n\n\n\n\n\n11.2 Exercise II\n\nWe might expect the IDS preference effect to change with infant age, such that older infants display longer looking times to IDS over ADS. How would you add a positive interaction effect of (cross-sectional) age as a predictor to the model (hint: it involves randomly sampling age for each child and adding an effect to the simulation code and model)? Try to think through the problem, get inspiration from the below plot, code up a solution, and only then click on “Show the code” to check how you might approach this.\n\n\n\nShow the code\n#The question here involves adding infant age as an interaction effect with SpeechStyle. We will approach this question by modifying the code that simulates subject-level data. Here, we will sample an age variable and pretend that we have standardised age so that its values fall between -0.5 and 0.5. We thus randomly sample age to assign one age to each subject. We also need to specify a slope value for the influence of subject age and place it in the start of the function; we will add subject_age = 200. Lastly, we need to change how we sum the values together, so that age has an effect on looking times, but also that the influence of age exerts different effects across the two speech styles.\n\nSimulateLTDataWithAge &lt;- function(\n  beta_age = 2000, #add effect of age\n  age_interaction_sd = 150, #add some jitter to age effect\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 6000,   # ADS intercept\n  mean_slope =  1000,   # effect of IDS\n  item_varyingintercept =  250,   # by-item random intercept sd\n  subject_varyingintercept = 500,   # by-subject random intercept sd\n  subject_varyingslope =  300,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 500) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope, age_interaction_sd), \n  r = rho,\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\", \"age_slope_sd\")\n) %&gt;%\n    mutate(subj_id = faux::make_id(nrow(.), \"S\")) %&gt;%\n    mutate(age_subj = runif(n_subj, min = -0.5, max = 0.5))\n\n  ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  ParameterValues %&gt;%\n    mutate(LT = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + ((beta_age + age_slope_sd) * age_subj * SpeechStyle) + e_si) %&gt;%\n  mutate(LT = LT + rexp(nrow(.), rate = 0.01)) %&gt;% #add a long tail to the distribution to simulate exgaussian distribution of looking times\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, age_subj, LT)\n}\n\nDataWithAgeSimulated &lt;- SimulateLTDataWithAge()\nDataWithAgeSimulated %&gt;%\nggplot() + \n  geom_point(aes(y = LT, x = age_subj, color = subj_id), alpha = 0.6, size = 1, show.legend = F) + \n  geom_smooth(method = \"lm\", se = TRUE, formula = y ~ x, aes(y = LT, x = age_subj)) +\n  ggtitle(\"Interaction Effect Between Age and SpeechStyle\") +\n  xlab(\"Age (standardised age)\") + \n  ylab('Looking Time (ms)') +\n  facet_wrap(~Register) +\n  scale_color_manual(values = viridis(n = 27)) +\n  plot_theme"
  },
  {
    "objectID": "content/GridSearch_03.html",
    "href": "content/GridSearch_03.html",
    "title": "Grid Searches and Sensitivity Analyses",
    "section": "",
    "text": "It should be clear from the previous sections that the data simulation process involves a multiverse of experimenter choices. One way to explore (and calm our fears about) the respective importance of these individual choices and their interactions would be to conduct a sensitivity analysis with a grid search of all available combinations among parameter values of interest. To do this, we can wrap our Simulation and Modelling function with a higher-level function that inputs a series of parameter combinations that we are interested in exploring further. Here is a suggestion for a function of this type. We can start by creating a matrix of parameter combinations that we are interested in.\n\nsubj_n &lt;- seq(10, 100, by = 10)\ntrial_n &lt;- seq(4, 12, by = 2)\nNumberOfModels &lt;- 25\n\nparam_combinations &lt;- expand.grid(subj_n = subj_n, trial_n = trial_n)\n\n\nrun_sims_grid_point &lt;- function(filename_full, trial_n, subj_n) {\n    ADS_n = trial_n/2\n    IDS_n = trial_n/2\n    n_subj = subj_n\n\n    dataSimulated &lt;- SimulateEffectSizeData(n_subj = n_subj,\n        n_ADS = ADS_n, n_IDS = IDS_n)\n\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n\n    sim_results &lt;- broom.mixed::tidy(model)\n\n    # append the results to a file\n    append &lt;- file.exists(filename_full)\n    write_csv(sim_results, filename_full, append = append)\n\n    # return the tidy table\n    sim_results\n}\n\n\n# let's make a new folder to store the output of the\n# simulation function:\nif (file.exists(here(\"sims_grid_search\"))) {\n    setwd(here(\"sims_grid_search\"))\n} else {\n    dir.create(here(\"sims_grid_search\"))\n    setwd(here(\"sims_grid_search\"))\n}\n\nfor (i in seq_len(nrow(param_combinations))) {\n    sim_params &lt;- param_combinations[i, ]\n    filename_full &lt;- paste0(here(\"sims_grid_search/test_grid_search_\"),\n        sim_params$subj_n, \"_\", sim_params$trial_n, \".csv\")\n    start_time &lt;- Sys.time()  # Start time\n    sims &lt;- purrr::map_df(1:NumberOfModels, ~run_sims_grid_point(filename_full = filename_full,\n        subj_n = sim_params$subj_n, trial_n = sim_params$trial_n))\n    end_time &lt;- Sys.time()  # End time\n    cat(\"Simulation\", i, \"Time elapsed:\", end_time - start_time,\n        \"\\n\")\n}\n\n\nsetwd(here(\"sims_grid_search\"))\nfile_names &lt;- list.files(pattern = \"*.csv\")\n\n# read in all CSV files into a list of dataframes\ndf_list &lt;- purrr::map(file_names, ~{\n    df &lt;- read.csv(.x)\n    df$filename &lt;- .x\n    df\n})\n\ndf &lt;- purrr::reduce(df_list, dplyr::bind_rows)\n\ndf_per_sim &lt;- df %&gt;%\n    filter(effect == \"fixed\") %&gt;%\n    filter(term == \"SpeechStyle\") %&gt;%\n    group_by(filename) %&gt;%\n    summarise(median_estimate = median(estimate), median_se = median(std.error),\n        power = mean(p.value &lt; 0.05))\n\nPowerGridData &lt;- df_per_sim %&gt;%\n    mutate(n_subj = as.numeric(sapply(strsplit(filename, \"_\"),\n        `[`, 4)), n_trial = as.factor(str_replace(sapply(strsplit(filename,\n        \"_\"), `[`, 5), pattern = \".csv\", \"\"))) %&gt;%\n    mutate(n_trial = factor(n_trial, levels = c(\"4\", \"6\", \"8\",\n        \"10\", \"12\")))\n\nggplot(PowerGridData) + geom_point(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_line(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_hline(yintercept = 0.8, linetype = 3) +\n    xlim(c(0, 110)) + xlab(\"Sample Size\") + ylab(\"Statistical Power\") +\n    ggtitle(\"Interaction among Sample Size & Repeated Measures\") +\n    scale_color_brewer(palette = \"Dark2\") + plot_theme",
    "crumbs": [
      "Part III, Grid Searches and Sensitivity Analyses"
    ]
  },
  {
    "objectID": "content/GridSearch_03.html#using-grid-searches-to-explore-the-multiverse",
    "href": "content/GridSearch_03.html#using-grid-searches-to-explore-the-multiverse",
    "title": "Grid Searches and Sensitivity Analyses",
    "section": "",
    "text": "It should be clear from the previous sections that the data simulation process involves a multiverse of experimenter choices. One way to explore (and calm our fears about) the respective importance of these individual choices and their interactions would be to conduct a sensitivity analysis with a grid search of all available combinations among parameter values of interest. To do this, we can wrap our Simulation and Modelling function with a higher-level function that inputs a series of parameter combinations that we are interested in exploring further. Here is a suggestion for a function of this type. We can start by creating a matrix of parameter combinations that we are interested in.\n\nsubj_n &lt;- seq(10, 100, by = 10)\ntrial_n &lt;- seq(4, 12, by = 2)\nNumberOfModels &lt;- 25\n\nparam_combinations &lt;- expand.grid(subj_n = subj_n, trial_n = trial_n)\n\n\nrun_sims_grid_point &lt;- function(filename_full, trial_n, subj_n) {\n    ADS_n = trial_n/2\n    IDS_n = trial_n/2\n    n_subj = subj_n\n\n    dataSimulated &lt;- SimulateEffectSizeData(n_subj = n_subj,\n        n_ADS = ADS_n, n_IDS = IDS_n)\n\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n\n    sim_results &lt;- broom.mixed::tidy(model)\n\n    # append the results to a file\n    append &lt;- file.exists(filename_full)\n    write_csv(sim_results, filename_full, append = append)\n\n    # return the tidy table\n    sim_results\n}\n\n\n# let's make a new folder to store the output of the\n# simulation function:\nif (file.exists(here(\"sims_grid_search\"))) {\n    setwd(here(\"sims_grid_search\"))\n} else {\n    dir.create(here(\"sims_grid_search\"))\n    setwd(here(\"sims_grid_search\"))\n}\n\nfor (i in seq_len(nrow(param_combinations))) {\n    sim_params &lt;- param_combinations[i, ]\n    filename_full &lt;- paste0(here(\"sims_grid_search/test_grid_search_\"),\n        sim_params$subj_n, \"_\", sim_params$trial_n, \".csv\")\n    start_time &lt;- Sys.time()  # Start time\n    sims &lt;- purrr::map_df(1:NumberOfModels, ~run_sims_grid_point(filename_full = filename_full,\n        subj_n = sim_params$subj_n, trial_n = sim_params$trial_n))\n    end_time &lt;- Sys.time()  # End time\n    cat(\"Simulation\", i, \"Time elapsed:\", end_time - start_time,\n        \"\\n\")\n}\n\n\nsetwd(here(\"sims_grid_search\"))\nfile_names &lt;- list.files(pattern = \"*.csv\")\n\n# read in all CSV files into a list of dataframes\ndf_list &lt;- purrr::map(file_names, ~{\n    df &lt;- read.csv(.x)\n    df$filename &lt;- .x\n    df\n})\n\ndf &lt;- purrr::reduce(df_list, dplyr::bind_rows)\n\ndf_per_sim &lt;- df %&gt;%\n    filter(effect == \"fixed\") %&gt;%\n    filter(term == \"SpeechStyle\") %&gt;%\n    group_by(filename) %&gt;%\n    summarise(median_estimate = median(estimate), median_se = median(std.error),\n        power = mean(p.value &lt; 0.05))\n\nPowerGridData &lt;- df_per_sim %&gt;%\n    mutate(n_subj = as.numeric(sapply(strsplit(filename, \"_\"),\n        `[`, 4)), n_trial = as.factor(str_replace(sapply(strsplit(filename,\n        \"_\"), `[`, 5), pattern = \".csv\", \"\"))) %&gt;%\n    mutate(n_trial = factor(n_trial, levels = c(\"4\", \"6\", \"8\",\n        \"10\", \"12\")))\n\nggplot(PowerGridData) + geom_point(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_line(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_hline(yintercept = 0.8, linetype = 3) +\n    xlim(c(0, 110)) + xlab(\"Sample Size\") + ylab(\"Statistical Power\") +\n    ggtitle(\"Interaction among Sample Size & Repeated Measures\") +\n    scale_color_brewer(palette = \"Dark2\") + plot_theme",
    "crumbs": [
      "Part III, Grid Searches and Sensitivity Analyses"
    ]
  },
  {
    "objectID": "content/GridSearch_03.html#exercises-to-check-understanding",
    "href": "content/GridSearch_03.html#exercises-to-check-understanding",
    "title": "Grid Searches and Sensitivity Analyses",
    "section": "2 Exercises to Check Understanding",
    "text": "2 Exercises to Check Understanding\n\n2.1 Exercise VI\nHow would you adapt the above grid search code to investigate the effect of varying the number of subjects and different effect sizes?\n\n\nShow the code\nif (file.exists(here(\"sims_grid_search_exercise_6\"))) {\n    setwd(here(\"sims_grid_search_exercise_6\"))\n} else {\n    dir.create(here(\"sims_grid_search_exercise_6\"))\n    setwd(here(\"sims_grid_search_exercise_6\"))\n}\n\nsubj_n &lt;- seq(2, 50, by = 3)\neffectsize &lt;- seq(0.3, 0.9, by = 0.3)\nNumberOfModels &lt;- 400\n\nparam_combinations &lt;- expand.grid(subj_n = subj_n, effectsize = effectsize)\n\nrun_sims_grid_point &lt;- function(filename_full, ef, subj_n) {\n    ef = effectsize\n    n_subj = subj_n\n\n    dataSimulated &lt;- SimulateEffectSizeData(n_subj = n_subj,\n        mean_slope = ef)\n\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n\n    sim_results &lt;- broom.mixed::tidy(model)\n\n    # append the results to a file\n    append &lt;- file.exists(filename_full)\n    write_csv(sim_results, filename_full, append = append)\n\n    # return the tidy table\n    sim_results\n}\n\nfor (i in seq_len(nrow(param_combinations))) {\n    sim_params &lt;- param_combinations[i, ]\n    filename_full &lt;- paste0(here(\"sims_grid_search_exercise_6/test_grid_search_\"),\n        sim_params$subj_n, \"_\", sim_params$ef, \".csv\")\n    start_time &lt;- Sys.time()  # Start time\n    sims &lt;- purrr::map_df(1:NumberOfModels, ~run_sims_grid_point(filename_full = filename_full,\n        subj_n = sim_params$subj_n, ef = sim_params$effectsize))\n    end_time &lt;- Sys.time()  # End time\n    cat(\"Simulation\", i, \"Time elapsed:\", end_time - start_time,\n        \"\\n\")\n}\n\n\n\n\nShow the code\nsetwd(here(\"sims_grid_search_exercise_6\"))\nfile_names &lt;- list.files(pattern = \"*.csv\")\n\n# read in all CSV files into a list of dataframes\ndf_list &lt;- purrr::map(file_names, ~{\n    df &lt;- read.csv(.x)\n    df$filename &lt;- .x\n    df\n})\n\ndf &lt;- purrr::reduce(df_list, dplyr::bind_rows)\n\ndf_per_sim &lt;- df %&gt;%\n    filter(effect == \"fixed\") %&gt;%\n    filter(term == \"SpeechStyle\") %&gt;%\n    group_by(filename) %&gt;%\n    summarise(median_estimate = median(estimate), median_se = median(std.error),\n        power = mean(p.value &lt; 0.05))\n\nPowerGridData &lt;- df_per_sim %&gt;%\n    mutate(n_subj = as.numeric(sapply(strsplit(filename, \"_\"),\n        `[`, 4)), ef = as.factor(str_replace(sapply(strsplit(filename,\n        \"_\"), `[`, 5), pattern = \".csv\", \"\")))\n\nggplot(PowerGridData) + geom_point(aes(x = n_subj, y = power,\n    color = ef)) + geom_line(aes(x = n_subj, y = power, color = ef)) +\n    geom_hline(yintercept = 0.8, linetype = 3) + xlab(\"Sample Size\") +\n    ylab(\"Statistical Power\") + ggtitle(\"Interaction among Number of Subjects & Effect Size\") +\n    scale_color_brewer(palette = \"Dark2\") + plot_theme",
    "crumbs": [
      "Part III, Grid Searches and Sensitivity Analyses"
    ]
  },
  {
    "objectID": "content/03_GridSearch.html",
    "href": "content/03_GridSearch.html",
    "title": "Grid Searches and Sensitivity Analyses",
    "section": "",
    "text": "It should be clear from the previous sections that the data simulation process involves a multiverse of experimenter choices. One way to explore (and calm our fears about) the respective importance of these individual choices and their interactions would be to conduct a sensitivity analysis with a grid search of all available combinations among parameter values of interest. To do this, we can wrap our Simulation and Modelling function with a higher-level function that inputs a series of parameter combinations that we are interested in exploring further. Here is a suggestion for a function of this type. We can start by creating a matrix of parameter combinations that we are interested in.\n\nsubj_n &lt;- seq(10, 100, by = 10)\ntrial_n &lt;- seq(4, 12, by = 2)\nNumberOfModels &lt;- 25\n\nparam_combinations &lt;- expand.grid(subj_n = subj_n, trial_n = trial_n)\n\n\nrun_sims_grid_point &lt;- function(filename_full, trial_n, subj_n) {\n    ADS_n = trial_n/2\n    IDS_n = trial_n/2\n    n_subj = subj_n\n\n    dataSimulated &lt;- SimulateEffectSizeData(n_subj = n_subj,\n        n_ADS = ADS_n, n_IDS = IDS_n)\n\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n\n    sim_results &lt;- broom.mixed::tidy(model)\n\n    # append the results to a file\n    append &lt;- file.exists(filename_full)\n    write_csv(sim_results, filename_full, append = append)\n\n    # return the tidy table\n    sim_results\n}\n\n\n# let's make a new folder to store the output of the\n# simulation function:\nif (file.exists(here(\"sims_grid_search\"))) {\n    setwd(here(\"sims_grid_search\"))\n} else {\n    dir.create(here(\"sims_grid_search\"))\n    setwd(here(\"sims_grid_search\"))\n}\n\nfor (i in seq_len(nrow(param_combinations))) {\n    sim_params &lt;- param_combinations[i, ]\n    filename_full &lt;- paste0(here(\"sims_grid_search/test_grid_search_\"),\n        sim_params$subj_n, \"_\", sim_params$trial_n, \".csv\")\n    start_time &lt;- Sys.time()  # Start time\n    sims &lt;- purrr::map_df(1:NumberOfModels, ~run_sims_grid_point(filename_full = filename_full,\n        subj_n = sim_params$subj_n, trial_n = sim_params$trial_n))\n    end_time &lt;- Sys.time()  # End time\n    cat(\"Simulation\", i, \"Time elapsed:\", end_time - start_time,\n        \"\\n\")\n}\n\n\nsetwd(here(\"sims_grid_search\"))\nfile_names &lt;- list.files(pattern = \"*.csv\")\n\n# read in all CSV files into a list of dataframes\ndf_list &lt;- purrr::map(file_names, ~{\n    df &lt;- read.csv(.x)\n    df$filename &lt;- .x\n    df\n})\n\ndf &lt;- purrr::reduce(df_list, dplyr::bind_rows)\n\ndf_per_sim &lt;- df %&gt;%\n    filter(effect == \"fixed\") %&gt;%\n    filter(term == \"SpeechStyle\") %&gt;%\n    group_by(filename) %&gt;%\n    summarise(median_estimate = median(estimate), median_se = median(std.error),\n        power = mean(p.value &lt; 0.05))\n\nPowerGridData &lt;- df_per_sim %&gt;%\n    mutate(n_subj = as.numeric(sapply(strsplit(filename, \"_\"),\n        `[`, 4)), n_trial = as.factor(str_replace(sapply(strsplit(filename,\n        \"_\"), `[`, 5), pattern = \".csv\", \"\"))) %&gt;%\n    mutate(n_trial = factor(n_trial, levels = c(\"4\", \"6\", \"8\",\n        \"10\", \"12\")))\n\nggplot(PowerGridData) + geom_point(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_line(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_hline(yintercept = 0.8, linetype = 3) +\n    xlim(c(0, 110)) + xlab(\"Sample Size\") + ylab(\"Statistical Power\") +\n    ggtitle(\"Interaction among Sample Size & Repeated Measures\") +\n    scale_color_brewer(palette = \"Dark2\") + plot_theme"
  },
  {
    "objectID": "content/03_GridSearch.html#using-grid-searches-to-explore-the-multiverse",
    "href": "content/03_GridSearch.html#using-grid-searches-to-explore-the-multiverse",
    "title": "Grid Searches and Sensitivity Analyses",
    "section": "",
    "text": "It should be clear from the previous sections that the data simulation process involves a multiverse of experimenter choices. One way to explore (and calm our fears about) the respective importance of these individual choices and their interactions would be to conduct a sensitivity analysis with a grid search of all available combinations among parameter values of interest. To do this, we can wrap our Simulation and Modelling function with a higher-level function that inputs a series of parameter combinations that we are interested in exploring further. Here is a suggestion for a function of this type. We can start by creating a matrix of parameter combinations that we are interested in.\n\nsubj_n &lt;- seq(10, 100, by = 10)\ntrial_n &lt;- seq(4, 12, by = 2)\nNumberOfModels &lt;- 25\n\nparam_combinations &lt;- expand.grid(subj_n = subj_n, trial_n = trial_n)\n\n\nrun_sims_grid_point &lt;- function(filename_full, trial_n, subj_n) {\n    ADS_n = trial_n/2\n    IDS_n = trial_n/2\n    n_subj = subj_n\n\n    dataSimulated &lt;- SimulateEffectSizeData(n_subj = n_subj,\n        n_ADS = ADS_n, n_IDS = IDS_n)\n\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n\n    sim_results &lt;- broom.mixed::tidy(model)\n\n    # append the results to a file\n    append &lt;- file.exists(filename_full)\n    write_csv(sim_results, filename_full, append = append)\n\n    # return the tidy table\n    sim_results\n}\n\n\n# let's make a new folder to store the output of the\n# simulation function:\nif (file.exists(here(\"sims_grid_search\"))) {\n    setwd(here(\"sims_grid_search\"))\n} else {\n    dir.create(here(\"sims_grid_search\"))\n    setwd(here(\"sims_grid_search\"))\n}\n\nfor (i in seq_len(nrow(param_combinations))) {\n    sim_params &lt;- param_combinations[i, ]\n    filename_full &lt;- paste0(here(\"sims_grid_search/test_grid_search_\"),\n        sim_params$subj_n, \"_\", sim_params$trial_n, \".csv\")\n    start_time &lt;- Sys.time()  # Start time\n    sims &lt;- purrr::map_df(1:NumberOfModels, ~run_sims_grid_point(filename_full = filename_full,\n        subj_n = sim_params$subj_n, trial_n = sim_params$trial_n))\n    end_time &lt;- Sys.time()  # End time\n    cat(\"Simulation\", i, \"Time elapsed:\", end_time - start_time,\n        \"\\n\")\n}\n\n\nsetwd(here(\"sims_grid_search\"))\nfile_names &lt;- list.files(pattern = \"*.csv\")\n\n# read in all CSV files into a list of dataframes\ndf_list &lt;- purrr::map(file_names, ~{\n    df &lt;- read.csv(.x)\n    df$filename &lt;- .x\n    df\n})\n\ndf &lt;- purrr::reduce(df_list, dplyr::bind_rows)\n\ndf_per_sim &lt;- df %&gt;%\n    filter(effect == \"fixed\") %&gt;%\n    filter(term == \"SpeechStyle\") %&gt;%\n    group_by(filename) %&gt;%\n    summarise(median_estimate = median(estimate), median_se = median(std.error),\n        power = mean(p.value &lt; 0.05))\n\nPowerGridData &lt;- df_per_sim %&gt;%\n    mutate(n_subj = as.numeric(sapply(strsplit(filename, \"_\"),\n        `[`, 4)), n_trial = as.factor(str_replace(sapply(strsplit(filename,\n        \"_\"), `[`, 5), pattern = \".csv\", \"\"))) %&gt;%\n    mutate(n_trial = factor(n_trial, levels = c(\"4\", \"6\", \"8\",\n        \"10\", \"12\")))\n\nggplot(PowerGridData) + geom_point(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_line(aes(x = n_subj, y = power,\n    color = n_trial)) + geom_hline(yintercept = 0.8, linetype = 3) +\n    xlim(c(0, 110)) + xlab(\"Sample Size\") + ylab(\"Statistical Power\") +\n    ggtitle(\"Interaction among Sample Size & Repeated Measures\") +\n    scale_color_brewer(palette = \"Dark2\") + plot_theme"
  },
  {
    "objectID": "content/03_GridSearch.html#exercises-to-check-understanding",
    "href": "content/03_GridSearch.html#exercises-to-check-understanding",
    "title": "Grid Searches and Sensitivity Analyses",
    "section": "2 Exercises to Check Understanding",
    "text": "2 Exercises to Check Understanding\n\n2.1 Exercise VI\nHow would you adapt the above grid search code to investigate the effect of varying the number of subjects and different effect sizes?\n\n\nShow the code\nif (file.exists(here(\"sims_grid_search_exercise_6\"))) {\n    setwd(here(\"sims_grid_search_exercise_6\"))\n} else {\n    dir.create(here(\"sims_grid_search_exercise_6\"))\n    setwd(here(\"sims_grid_search_exercise_6\"))\n}\n\nsubj_n &lt;- seq(2, 50, by = 3)\neffectsize &lt;- seq(0.3, 0.9, by = 0.3)\nNumberOfModels &lt;- 400\n\nparam_combinations &lt;- expand.grid(subj_n = subj_n, effectsize = effectsize)\n\nrun_sims_grid_point &lt;- function(filename_full, ef, subj_n) {\n    ef = effectsize\n    n_subj = subj_n\n\n    dataSimulated &lt;- SimulateEffectSizeData(n_subj = n_subj,\n        mean_slope = ef)\n\n    model &lt;- lmer(EF ~ 1 + SpeechStyle + (1 | item_id) + (1 +\n        SpeechStyle | subj_id), data = dataSimulated)\n\n    sim_results &lt;- broom.mixed::tidy(model)\n\n    # append the results to a file\n    append &lt;- file.exists(filename_full)\n    write_csv(sim_results, filename_full, append = append)\n\n    # return the tidy table\n    sim_results\n}\n\nfor (i in seq_len(nrow(param_combinations))) {\n    sim_params &lt;- param_combinations[i, ]\n    filename_full &lt;- paste0(here(\"sims_grid_search_exercise_6/test_grid_search_\"),\n        sim_params$subj_n, \"_\", sim_params$ef, \".csv\")\n    start_time &lt;- Sys.time()  # Start time\n    sims &lt;- purrr::map_df(1:NumberOfModels, ~run_sims_grid_point(filename_full = filename_full,\n        subj_n = sim_params$subj_n, ef = sim_params$effectsize))\n    end_time &lt;- Sys.time()  # End time\n    cat(\"Simulation\", i, \"Time elapsed:\", end_time - start_time,\n        \"\\n\")\n}\n\n\n\n\nShow the code\nsetwd(here(\"sims_grid_search_exercise_6\"))\nfile_names &lt;- list.files(pattern = \"*.csv\")\n\n# read in all CSV files into a list of dataframes\ndf_list &lt;- purrr::map(file_names, ~{\n    df &lt;- read.csv(.x)\n    df$filename &lt;- .x\n    df\n})\n\ndf &lt;- purrr::reduce(df_list, dplyr::bind_rows)\n\ndf_per_sim &lt;- df %&gt;%\n    filter(effect == \"fixed\") %&gt;%\n    filter(term == \"SpeechStyle\") %&gt;%\n    group_by(filename) %&gt;%\n    summarise(median_estimate = median(estimate), median_se = median(std.error),\n        power = mean(p.value &lt; 0.05))\n\nPowerGridData &lt;- df_per_sim %&gt;%\n    mutate(n_subj = as.numeric(sapply(strsplit(filename, \"_\"),\n        `[`, 4)), ef = as.factor(str_replace(sapply(strsplit(filename,\n        \"_\"), `[`, 5), pattern = \".csv\", \"\")))\n\nggplot(PowerGridData) + geom_point(aes(x = n_subj, y = power,\n    color = ef)) + geom_line(aes(x = n_subj, y = power, color = ef)) +\n    geom_hline(yintercept = 0.8, linetype = 3) + xlab(\"Sample Size\") +\n    ylab(\"Statistical Power\") + ggtitle(\"Interaction among Number of Subjects & Effect Size\") +\n    scale_color_brewer(palette = \"Dark2\") + plot_theme"
  },
  {
    "objectID": "content/DataSimulation_01.html",
    "href": "content/DataSimulation_01.html",
    "title": "Part I, Data Simulation",
    "section": "",
    "text": "In this first task, we will deal with a dependent variable that should be familiar to many researchers within developmental science: infant looking times. In our hypothetical study (modelled on ManyBabies1), infant participants are exposed to recordings of adult-directed speech (ADS) and infant-directed speech (IDS), and infants’ looking times to an unrelated visual stimulus is recorded as the primary dependent variable. The key question is whether there are any behavioural differences according to the set of stimuli (i.e., ADS vs. IDS) within each participant. To gain familiarity with the simulation process and to build up the structure for a simulation function that will help us when performing the power analysis in Part II, we will simulate data on the scale of looking times (i.e., 0-20,000ms). In the next section, we will extend this process to simulate effect size data.",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#a-description-of-the-example-and-aim-of-the-simulation",
    "href": "content/DataSimulation_01.html#a-description-of-the-example-and-aim-of-the-simulation",
    "title": "Part I, Data Simulation",
    "section": "",
    "text": "In this first task, we will deal with a dependent variable that should be familiar to many researchers within developmental science: infant looking times. In our hypothetical study (modelled on ManyBabies1), infant participants are exposed to recordings of adult-directed speech (ADS) and infant-directed speech (IDS), and infants’ looking times to an unrelated visual stimulus is recorded as the primary dependent variable. The key question is whether there are any behavioural differences according to the set of stimuli (i.e., ADS vs. IDS) within each participant. To gain familiarity with the simulation process and to build up the structure for a simulation function that will help us when performing the power analysis in Part II, we will simulate data on the scale of looking times (i.e., 0-20,000ms). In the next section, we will extend this process to simulate effect size data.",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#determining-the-experimental-parameters",
    "href": "content/DataSimulation_01.html#determining-the-experimental-parameters",
    "title": "Part I, Data Simulation",
    "section": "2 Determining the Experimental Parameters",
    "text": "2 Determining the Experimental Parameters\nBefore we can start to simulate data, we need to be very clear about the study design. This clarity is important because we need to explicitly define the parameters that we assume govern the process of data generation. If we are designing a similar study to that of ManyBabies1, then we are dealing with a within-subjects, between-items study; that is, each and every subject receives both ADS and IDS stimuli (within-subject), but each stimulus is either ADS or IDS (between-items).\nBecause infants are not the most patient of participants, perhaps a realistic study design would allow researchers to expose infants to 6 recordings of ADS and 6 recordings of IDS. And let’s say that a realistic sample size in our imaginary laboratory would be around 25 participants. This would imply a total of 300 observations in this study (i.e., 6 + 6 recording stimuli for each of the 25 children). Let’s set start by setting these experimental parameters.\n\n# set number of subjects and items\nn_subj &lt;- 25 # number of infant participants\nn_ADS  &lt;-  6 # number of ADS stimuli\nn_IDS  &lt;-  6 # number of IDS stimuli",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#data-generating-parameters",
    "href": "content/DataSimulation_01.html#data-generating-parameters",
    "title": "Part I, Data Simulation",
    "section": "3 Data Generating Parameters",
    "text": "3 Data Generating Parameters\nNow that we have an overview of the experimental design, we can start to consider a reasonable underlying statistical model. In the following sections, we will gradually build up the parameters for a linear mixed-effects model of the following type, as described in the lecture:\n\\[\nLooking Time = \\beta^{ADS} + VaryingIntercept^{subj} + VaryingIntercept^{item} + (\\beta^{IDS} + VaryingSlope^{subj}) \\cdot SpeechStyle + \\varepsilon\n\\] According to this formula, the process of data generation means that our dependent variable of looking time is composed of a linear combination of the following fixed parameters:\n\nthe average ADS intercept capturing the mean baseline tendency to attend to ADS, β(ADS)\nthe average influence of IDS on this baseline attention, β(IDS)\n\nThere are also three varying effects:\n\na by-subject random intercept, VaryingIntercept(subj),\na by-item random intercept, VaryingIntercept(item)\na by-subject random slope, VaryingSlope(subj)\n\nAnd lastly:\n\na trial-level residual error, ε\n\nThis formula paves a clear way forward for our process of data simulation. In the next section, we will build up a statistical model step by step, defining variables in the code as we go along that reflect our choices for the different parameters.",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#choosing-values-for-fixed-effect-parameters",
    "href": "content/DataSimulation_01.html#choosing-values-for-fixed-effect-parameters",
    "title": "Part I, Data Simulation",
    "section": "4 Choosing Values for Fixed Effect Parameters",
    "text": "4 Choosing Values for Fixed Effect Parameters\nLet’s start by setting the fixed-effect parameters of SpeechStyle (β₀ + β₁*SpeechStyle). How should we set these parameters? A good place to start would be to be guided by what we know about looking time distributions in infant experiments. For example, we could imagine average infant looking times to be around 6 seconds (i.e., 6000ms) and for IDS stimuli to increase infant looking time by 1 second (i.e., 1000ms). Let’s go ahead and set these values as parameters in our simulation.\n\n# set fixed effect parameters\nmean_intercept &lt;- 6000  # ADS intercept; i.e., the grand mean, β₀\nmean_slope &lt;- 1000  # slope; i.e, effect of IDS, β₁",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#choosing-values-for-varying-intercept-parameters",
    "href": "content/DataSimulation_01.html#choosing-values-for-varying-intercept-parameters",
    "title": "Part I, Data Simulation",
    "section": "5 Choosing Values for Varying Intercept Parameters",
    "text": "5 Choosing Values for Varying Intercept Parameters\nWhen we’re modelling data from experiments involving individuals (like infants in this case), it’s essential to account for the fact that each individual may have unique baseline reactions to the speech stimuli. Similarly, the effect of the stimuli on infant looking times might vary across different instances of the stimulus items.\nTo address this, we introduce random intercept values for subjects and items by coding the standard deviation of the random intercepts and sampling from a normal distribution. This reflects the range of differences we might observe among subjects’ reactions and the effects of different stimulus items.\n\n# set random effect parameters\nsubject_varyingintercept &lt;- 500  # by-subject random intercept sd\nitem_varyingintercept &lt;- 250  # by-item random intercept sd",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#choosing-value-for-varying-slope-parameter",
    "href": "content/DataSimulation_01.html#choosing-value-for-varying-slope-parameter",
    "title": "Part I, Data Simulation",
    "section": "6 Choosing Value for Varying Slope Parameter",
    "text": "6 Choosing Value for Varying Slope Parameter\nWe also need to acknowledge that the magnitude of the effect of IDS stimuli may vary across individual infants. Some infants might be more responsive to IDS stimuli than others, leading to variation in the differences in looking times across speech styles. We therefore introduce a slope parameter that varies by subject. When we introduce random slopes to a model, we need to consider potential correlations between these varying slopes and the varying intercepts. This is because if there is a correlation between the way individuals (infants, in this case) respond to the IDS stimuli (reflected in the varying slopes) and their baseline behaviors (reflected in the varying intercepts), it can affect our model’s predictions. For instance, if infants who naturally have longer attention spans (reflected in higher random intercepts) also tend to show stronger responses to IDS stimuli (reflected in steeper random slopes), ignoring this correlation might lead to biased estimates. Including a correlation matrix allows us to explicitly account for these potential correlations, ensuring that our model accurately captures the relationships between different sources of variability in the data and produces more reliable results. Hence, in the following code, we include a correlation matrix, specifying a weak correlation between the varying intercepts and varying slopes of infant participants. Lastly, we incorporate a residual error term to account for any unexplained sources of variability in the model.\n\n# set more random effect and error parameters\nsubject_varyingslope &lt;- 300  # by-subject random slope sd\nrho &lt;- 0.2  # correlation between intercept and slope\nsigma &lt;- 500  # residual (error) sd",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#simulate-stimulus-items",
    "href": "content/DataSimulation_01.html#simulate-stimulus-items",
    "title": "Part I, Data Simulation",
    "section": "7 Simulate Stimulus Items",
    "text": "7 Simulate Stimulus Items\nNow it’s time to create a dataset that lists, for each stimulus item, the speech style it is in and its varying properties on infants’ looking times. To set the parameter for varying item intercept, we are going to specify the standard deviation that we expect items to exhibit in the parameter, item_varyingintercept, in the below code. That is, we sample values from a normal distribution using the rnorm() function, with a mean of 0 and standard deviation of item_varyingintercept. For the varying item variable, we also need to assign a unique identifer to each of the 16 speech stimuli and designate whether the stimuli are ADS or IDS, with the first 8 being ADS and the next 8 being IDS. We are going to use the faux package to carry this out.\n\n# simulate a sample of items\n# total number of items = n_ADS + n_IDS\nitems &lt;- data.frame(\n  Register = rep(c(\"ADS\", \"IDS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% #add so that we have numeric predictors\n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\nTo get to better grips with the simulation process, let’s visualise the data and take a look:\n\nglimpse(items)\n\nRows: 12\nColumns: 4\n$ Register          &lt;chr&gt; \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"IDS\", \"ID…\n$ item_intercept_sd &lt;dbl&gt; -301.76644, 69.35731, 271.11029, -586.42443, 107.281…\n$ SpeechStyle       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1\n$ item_id           &lt;chr&gt; \"I01\", \"I02\", \"I03\", \"I04\", \"I05\", \"I06\", \"I07\", \"I0…\n\nggplot(items, aes(1, item_intercept_sd, fill = Register, color = Register)) +\n    geom_rain(alpha = 0.8, boxplot.args = list(color = \"black\",\n        outlier.shape = NA)) + ggtitle(\"Varying Intercept Terms for Stimulus Item\") +\n    ylab(\"SD of Item Intercept (ms)\") + facet_wrap(~Register) +\n    scale_fill_brewer(palette = \"Dark2\") + scale_color_brewer(palette = \"Dark2\") +\n    plot_theme + theme(axis.title.x = element_blank(), axis.text.x = element_blank(),\n    axis.ticks.x = element_blank())",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#simulate-the-sampling-of-subjects",
    "href": "content/DataSimulation_01.html#simulate-the-sampling-of-subjects",
    "title": "Part I, Data Simulation",
    "section": "8 Simulate the sampling of subjects",
    "text": "8 Simulate the sampling of subjects\nThe process of simulating varying intercepts varying slopes data for subjects is slightly more complex than that of items. This process is slightly more complex than before because we cannot simply sample the intercept values independently from the slope values using rnorm(). Instead, we need to sample pairs of values for each subject from a bivariate normal distribution because we need to account for patterns in the data among those infants who have a high looking time baseline in ADS and the effects of IDS. We will use the rnorm_multi() function from the faux package (DeBruine 2020) to carry this out. This function allows us to specify the means, and standard deviations (sd) for each variable, along with the correlations (rho), which in this case will be a single value applied to all pairs.\n\n# simulate a sample of subjects\n# sample from a multivariate random distribution \nsubjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, # means for random effects are always 0\n  sd = c(subject_varyingintercept, subject_varyingslope), # note that we set the SDs further up in the code when specifying varying intercepts and sloeps.\n  r = rho, # set correlation, see ?faux::rnorm_multi\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\")\n) %&gt;%\n  mutate(subj_id = faux::make_id(nrow(.), \"S\")) # add subject ids that correspond to the number of rows simulated.\n\nAgain, let’s visualise this process, so that we are sure what the code is doing.\n\nglimpse(subjects)\n\nRows: 25\nColumns: 3\n$ subject_intercept_sd &lt;dbl&gt; 316.45486, -47.32471, -501.32994, 130.05144, 198.…\n$ subject_slope_sd     &lt;dbl&gt; 453.69360, 78.39230, 46.78022, -404.79294, 351.84…\n$ subj_id              &lt;chr&gt; \"S01\", \"S02\", \"S03\", \"S04\", \"S05\", \"S06\", \"S07\", …\n\nsubjects %&gt;%\n    pivot_longer(cols = starts_with(\"subject\"), names_to = \"Parameters\",\n        values_to = \"value\") %&gt;%\n    ggplot() + geom_density(aes(value, fill = Parameters), alpha = 0.8) +\n    xlim(c(-4 * subject_varyingintercept, 4 * subject_varyingintercept)) +\n    facet_wrap(~Parameters) + ggtitle(\"Varying Intercept and Slope Terms for Subjects\") +\n    xlab(\"Looking Times (ms)\") + plot_theme + scale_fill_brewer(palette = \"Dark2\") +\n    theme(axis.title.y = element_blank(), axis.text.y = element_blank(),\n        axis.ticks.y = element_blank())",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#time-to-put-it-all-together",
    "href": "content/DataSimulation_01.html#time-to-put-it-all-together",
    "title": "Part I, Data Simulation",
    "section": "9 Time to Put It All Together",
    "text": "9 Time to Put It All Together\nBecause all subjects respond to all stimulus items, we can create a dataset with every possible combination of the rows in the simulated subject and item datasets. For this we use the tidyverse function crossing(). To introduce inherent fluctuations in trial-by-trial performance, we also incorporate random error into each trial at this stage, based on our sigma value (specified above). The output of this approach means that our dataset captures the full range of subject-item interactions while accounting for unpredictable variations in individual performance across trials.\n\n# cross subject and item IDs; add an error term\nParameterValues &lt;- crossing(subjects, items) %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n\nglimpse(ParameterValues)\n\nRows: 300\nColumns: 8\n$ subject_intercept_sd &lt;dbl&gt; -1252.9874, -1252.9874, -1252.9874, -1252.9874, -…\n$ subject_slope_sd     &lt;dbl&gt; 66.65159, 66.65159, 66.65159, 66.65159, 66.65159,…\n$ subj_id              &lt;chr&gt; \"S08\", \"S08\", \"S08\", \"S08\", \"S08\", \"S08\", \"S08\", …\n$ Register             &lt;chr&gt; \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"ADS\", \"IDS\", …\n$ item_intercept_sd    &lt;dbl&gt; -586.42443, -301.76644, 69.35731, 107.28117, 126.…\n$ SpeechStyle          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0…\n$ item_id              &lt;chr&gt; \"I04\", \"I01\", \"I02\", \"I05\", \"I06\", \"I03\", \"I12\", …\n$ e_si                 &lt;dbl&gt; -17.380195, -334.816790, -3.802378, 888.542224, -…\n\n\nNow we have specified the parameters in ParameterValues, we are ready to add up everything together to create the response variable (i.e., infant looking times in milliseconds).\n\n# calculate the response variable\nSimulatedLT &lt;- ParameterValues %&gt;%\n  mutate(LT = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + e_si) %&gt;% #sum together overall intercept, varying subject and item intercepts, varying subject slopes, and random error.\n  mutate(LT = LT + rexp(nrow(.), rate = 0.01)) %&gt;% #add a long tail to the distribution to simulate exgaussian distribution of looking times\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, LT)\n\nLet’s have a look at what the data we have generated looks like:\n\n# Plot of how overall looking time distributions differ\n# across ADS and IDS\nSimulatedLT %&gt;%\n    ggplot() + geom_density(aes(LT, fill = Register), alpha = 0.8) +\n    xlim(c(2400, 15000)) + ggtitle(\"Simulated Distributions for ADS and IDS\") +\n    plot_theme + scale_fill_brewer(palette = \"Dark2\") + theme(axis.title.y = element_blank(),\n    axis.text.y = element_blank(), axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n# Plot of how looking times of indvidual subjects differ\n# across the two speech style\nSimulatedLT %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(LT), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Individual Subject Looking Times across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Looking Time (ms)\") + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#with-the-initial-setup-done-lets-automatise-with-a-function",
    "href": "content/DataSimulation_01.html#with-the-initial-setup-done-lets-automatise-with-a-function",
    "title": "Part I, Data Simulation",
    "section": "10 With the Initial Setup Done, Let’s Automatise with a Function!",
    "text": "10 With the Initial Setup Done, Let’s Automatise with a Function!\nNow that we’ve simulated a dataset with the necessary properties, suitable for sophisticated linear mixed effects models, we can streamline the process by encapsulating all the preceding code into a custom function. This function will accept the parameters we defined earlier as arguments, with default values set to our chosen parameters.\n\n# set up the custom data simulation function\nSimulateLTData &lt;- function(\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 6000,   # ADS intercept\n  mean_slope =  1000,   # effect of IDS\n  item_varyingintercept =  250,   # by-item random intercept sd\n  subject_varyingintercept = 500,   # by-subject random intercept sd\n  subject_varyingslope =  300,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 500) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope), \n  r = rho,\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\")\n) %&gt;%\n  mutate(subj_id = faux::make_id(nrow(.), \"S\"))\n\n  ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  # calculate the response variable\n  ParameterValues %&gt;%\n    mutate(LT = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + e_si) %&gt;% #sum together overall intercept, varying subject and item intercepts, varying subject slopes, and random error.\n  mutate(LT = LT + rexp(nrow(.), rate = 0.01)) %&gt;% #add a long tail to the distribution to simulate exgaussian distribution of looking times\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, LT)\n}\n\nHaving condense all the preceding steps into a single function and returning a dataset with the specified parameters, we are now empowered to effortlessly experiment with different parameters or generate multiple datasets for power analysis purposes.\nFor example, we can easily generate a dataset with the effect of IDS being 3000ms instead of only 1000ms by specifying the following\n\nSimulatedDataWithIDSslopeOf3000 &lt;- SimulateLTData(mean_slope = 3000)\n\n# Plot of how looking times of indvidual subjects differ\n# across the two speech style\nSimulatedDataWithIDSslopeOf3000 %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(LT), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Individual Subject Looking Times across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Looking Time (ms)\") + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme\n\nWarning: Duplicated aesthetics after name standardisation: alpha",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  },
  {
    "objectID": "content/DataSimulation_01.html#exercises-to-check-understanding",
    "href": "content/DataSimulation_01.html#exercises-to-check-understanding",
    "title": "Part I, Data Simulation",
    "section": "11 Exercises to Check Understanding",
    "text": "11 Exercises to Check Understanding\n\n11.1 Exercise I\n\nHow would you adapt the above code to generate a dataset with 500 participants and no effect of SpeechStyle (i.e., distributions similar to the below plot)? Try to get inspiration from the below plot, code up a solution, and only then click on “Show the code” to check how you might approach this.\n\n\n\nShow the code\n# With our new SimulateLTData() function, the answer here\n# is fairly straightforward! We can simply specify that we\n# want to simulate 500 subjects and want a mean slope of 0,\n# like so:\n\nLTDataSimulated &lt;- SimulateLTData(n_subj = 500, mean_slope = 0)\n\nLTDataSimulated %&gt;%\n    group_by(subj_id, Register) %&gt;%\n    dplyr::summarise(medLT = mean(LT), .groups = \"drop\") %&gt;%\n    ggplot(aes(x = Register, y = medLT, fill = Register)) + geom_rain(alpha = 0.8,\n    rain.side = \"f1x1\", id.long.var = \"subj_id\", point.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42)), line.args.pos = list(position = position_jitter(width = 0.04,\n        height = 0, seed = 42))) + scale_fill_brewer(palette = \"Dark2\") +\n    ggtitle(\"Looking Time Differences across Speech Styles\") +\n    xlab(\"Speech Style\") + ylab(\"Looking Time (ms)\") + scale_color_manual(values = viridis(n = 27)) +\n    plot_theme\n\n\n\n\n\n\n\n\n\n\n\n11.2 Exercise II\n\nWe might expect the IDS preference effect to change with infant age, such that older infants display longer looking times to IDS over ADS. How would you add a positive interaction effect of (cross-sectional) age as a predictor to the model (hint: it involves randomly sampling age for each child and adding an effect to the simulation code and model)? Try to think through the problem, get inspiration from the below plot, code up a solution, and only then click on “Show the code” to check how you might approach this.\n\n\n\nShow the code\n#The question here involves adding infant age as an interaction effect with SpeechStyle. We will approach this question by modifying the code that simulates subject-level data. Here, we will sample an age variable and pretend that we have standardised age so that its values fall between -0.5 and 0.5. We thus randomly sample age to assign one age to each subject. We also need to specify a slope value for the influence of subject age and place it in the start of the function; we will add subject_age = 200. Lastly, we need to change how we sum the values together, so that age has an effect on looking times, but also that the influence of age exerts different effects across the two speech styles.\n\nSimulateLTDataWithAge &lt;- function(\n  beta_age = 2000, #add effect of age\n  age_interaction_sd = 150, #add some jitter to age effect\n  n_subj = 24,   # number of subjects\n  n_ADS  = 6,   # number of ADS stimuli\n  n_IDS =  6,   # number of IDS stimuli\n  mean_intercept = 6000,   # ADS intercept\n  mean_slope =  1000,   # effect of IDS\n  item_varyingintercept =  250,   # by-item random intercept sd\n  subject_varyingintercept = 500,   # by-subject random intercept sd\n  subject_varyingslope =  300,   # by-subject random slope sd\n  rho = 0.2,   # correlation between intercept and slope\n  sigma = 500) { # residual (standard deviation)\n\n  items &lt;- data.frame(\n  Register = rep(c(\"IDS\", \"ADS\"), c(n_ADS, n_IDS)),\n  item_intercept_sd = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_varyingintercept)\n) %&gt;% \n  mutate(SpeechStyle = recode(Register, \"ADS\" = 0, \"IDS\" = 1)) %&gt;% \n  mutate(item_id = faux::make_id(nrow(.), \"I\"))\n\n  subjects &lt;- faux::rnorm_multi(\n  n = n_subj, \n  mu = 0, \n  sd = c(subject_varyingintercept, subject_varyingslope, age_interaction_sd), \n  r = rho,\n  varnames = c(\"subject_intercept_sd\", \"subject_slope_sd\", \"age_slope_sd\")\n) %&gt;%\n    mutate(subj_id = faux::make_id(nrow(.), \"S\")) %&gt;%\n    mutate(age_subj = runif(n_subj, min = -0.5, max = 0.5))\n\n  ParameterValues &lt;- crossing(subjects, items)  %&gt;%\n    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma))\n  \n  ParameterValues %&gt;%\n    mutate(LT = mean_intercept + subject_intercept_sd + item_intercept_sd + (mean_slope + subject_slope_sd) * SpeechStyle + ((beta_age + age_slope_sd) * age_subj * SpeechStyle) + e_si) %&gt;%\n  mutate(LT = LT + rexp(nrow(.), rate = 0.01)) %&gt;% #add a long tail to the distribution to simulate exgaussian distribution of looking times\n  dplyr::select(subj_id, item_id, Register, SpeechStyle, age_subj, LT)\n}\n\nDataWithAgeSimulated &lt;- SimulateLTDataWithAge()\nDataWithAgeSimulated %&gt;%\nggplot() + \n  geom_point(aes(y = LT, x = age_subj, color = subj_id), alpha = 0.6, size = 1, show.legend = F) + \n  geom_smooth(method = \"lm\", se = TRUE, formula = y ~ x, aes(y = LT, x = age_subj)) +\n  ggtitle(\"Interaction Effect Between Age and SpeechStyle\") +\n  xlab(\"Age (standardised age)\") + \n  ylab('Looking Time (ms)') +\n  facet_wrap(~Register) +\n  scale_color_manual(values = viridis(n = 27)) +\n  plot_theme",
    "crumbs": [
      "Part I, Data Simulation"
    ]
  }
]