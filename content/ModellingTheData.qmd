---
title: Part II, Modelling the Simulated Data
editor_options: 
  chunk_output_type: console
---

## Choosing Values for Fixed Effect Parameters

```{r setup, include=FALSE}
#if you don't have the pacman package loaded on your computer, uncomment the next line, install pacman, and load in the required packages
options(repos = "https://cran.r-project.org/")
install.packages('pacman')
#load the required packages:
pacman::p_load(knitr, # rendering of .Rmd file
               lme4, # model specification / estimation
               afex, # anova and deriving p-values from lmer
               broom.mixed, # extracting data from model fits
               faux, # generate correlated values
               tidyverse, # data wrangling and visualisation
               ggridges, #visualisation
               viridis, # color schemes for visualisation
               kableExtra, #helps with knitting the .Rmd file
               cowplot, #visualisation tool to include multiple plots
               ggrain, #visualisation tool for raincloud plots
               dplyr,
               here,
               tidyr
               )

set.seed(1234)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE, fig.width=12, fig.height=11, fig.fullwidth=TRUE)

plot_theme <- 
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5, size = 18), 
        axis.text.x = element_text(size = 13), 
        axis.title.x = element_text(size = 13), 
        axis.text.y = element_text(size = 12), 
        axis.title.y = element_text(size = 13),
        strip.background = element_rect(color="white", fill="white", size=1.5, linetype="solid"))

```

```{r, include=FALSE}
# set up the custom data simulation function
SimulateLTData <- function(
  n_subj = 24,   # number of subjects
  n_ADS  = 2,   # number of ingroup stimuli
  n_IDS =  2,   # number of outgroup stimuli
  beta_0 = 7000,   # grand mean
  beta_1 =  2000,   # effect of category
  item_sd =  200,   # by-item random intercept sd
  tau_0 = 2000,   # by-subject random intercept sd
  tau_1 =  1000,   # by-subject random slope sd
  rho = 0.2,   # correlation between intercept and slope
  sigma = 500) { # residual (standard deviation)

  items <- data.frame(
  #item_id = seq_len(n_ADS + n_IDS),
  Register = rep(c("IDS", "ADS"), c(n_ADS, n_IDS)),
  O_0i = rnorm(n = n_ADS + n_IDS, mean = 0, sd = item_sd)) %>% 
  mutate(item_id = faux::make_id(nrow(.), "I")) %>%
  mutate(SpeechStyle = recode(Register, "ADS" = -0.5, "IDS" = +0.5))

  # simulate a sample of subjects

# sample from a multivariate random distribution 
  subjects <- faux::rnorm_multi(
  n = n_subj, 
  mu = 0, # means for random effects are always 0
  sd = c(tau_0, tau_1), # set SDs
  r = rho, # set correlation, see ?faux::rnorm_multi
  varnames = c("T_0s", "T_1s")
) %>%
  mutate(subj_id = faux::make_id(nrow(.), "S"))

  ParameterValues <- crossing(subjects, items)  %>%
    mutate(e_si = rnorm(nrow(.), mean = 0, sd = sigma)) %>%
    dplyr::select(subj_id, item_id, Register, SpeechStyle, everything())
  
  dat_sim <- ParameterValues %>%
    mutate(LT = beta_0 + T_0s + O_0i + (beta_1 + T_1s) * SpeechStyle + e_si) %>%
    mutate(LT = LT + rexp(nrow(.), rate = 0.0003)) %>%
    dplyr::select(subj_id, item_id, Register, SpeechStyle, LT)
}
```

## Modelling the Simulated Data

Let's think about how we want to run a generalised linear mixed-effects model of the data. For a varying intercepts, varying slopes model for each subject, we could run the following model with the lmer syntax as follows:

* LT ~ 1 + SpeechStyle + (1 | item_id) + (1 + SpeechStyle | subj_id)

In this model, LT is the looking time response variable; 1 corresponds to the average intercept; SpeechStyle is the predictor for the ADS/IDS manipulation for item i; (1 | item_id) specifies a by-subject random intercept (O_0i); (1 + SpeechStyle | subj_id) specifies a subject-specific random intercept (T_0s) plus the subject-specific random slope of SpeechStyle (T_1s). The error term (e_si) is automatically included in all models, so is left implicit in the above formula.  The terms in parentheses with the “pipe” separator (|) define the random effects structure. For each of these bracketed terms, the left-hand side of the pipe names the effects you wish to allow to vary and the right hand side names the variable identifying the levels of the random factor over which the terms vary (e.g., subjects or items). The first term, (1 | item_id) allows the intercept (1) to vary over the random factor of items (item_id). This is an instruction to estimate the parameter underlying the O_0i values, namely omega_0. The second term, (1 + X_i | subj_id), allows both the intercept and the effect of category (coded by X_i) to vary over the random factor of subjects (subj_id). It is an instruction to estimate the three parameters that underlie the T_0s and T_1s values, namely tau_0, tau_1, and rho.

Given that looking time data tends to be right-skewed (and we added an exponential component to simulation to emulate this), we can model the data using a logarithmic link function to take this into account. The GLMM would look as follows. We will use the summary() function to view the results.

```{r}
dataSimulated <- SimulateLTData()

model <- glmer(LT ~ 1 + SpeechStyle + (1 | item_id) + (1 + SpeechStyle | subj_id), 
               data = dataSimulated,
               family = Gamma(link = "log"))

summary(model)
```

The estimates in this model are on the logarithmic scale; we can exponentiate the model estimates to convert back to the scale of milliseconds, and if we do so, we can see that the model estimates resemble the looking times we simulated in the previous exercise. 

## Running the Power Analysis
Now we have two essential components to perform a simulation-based power analysis: i) a code pipeline to generate data for our research question and ii) a clear idea of how we want to model the data. Now it's time to run the actual power analysis. The way we do this is to specify an effect, run a model and count how many of the models show significant effects (i.e., the ground truth). For this, we would like a function that capitalises on our previous SimulateLTData() function; that is, if we include both the simulation and modelling of the data in one function, we can simplify the process of performing a power analysis. We will call this function SimulateAndModelLTData(), and we will use broom.mixed::tidy(model) to obtain a dataframe with the relevant results.

```{r, warning = FALSE}
# simulate, analyze, and return a table of parameter estimates
SimulateAndModelLTData <- function(...) {
  dataSimulated <- SimulateLTData()
  
  model <- lmer(LT ~ 1 + SpeechStyle + (1 | item_id) + (1 + SpeechStyle | subj_id),
                data = dataSimulated)
                #family = gaussian(link = "log"))
  
  broom.mixed::tidy(model)
}
SimulateAndModelLTData()
```

Now we have a function to generate data, run our model and spit out the results! Now it's time to repeat a few hundred times, so that we can calculate how much power we have with our given parameters (i.e., how often the ground truth is discovered given the data and model chosen). We are going to use map_df() to run the simulation and modelling function 100 times and write it to a .csv file.

```{r, warning = FALSE}
# run simulations and save to a file
n_runs <- 100 # use at least 100 to get stable estimates
simulations <- purrr::map_df(1:n_runs, ~ SimulateAndModelLTData())
write_csv(simulations, "LTsimulations.csv")
```

If run correctly, that should have produced a .csv file with model results from each new simulation of data. Let's read in the results and have a look at what they say!

```{r, warning = FALSE}
# read saved simulation data
sims <- read_csv("LTsimulations.csv", col_types = cols(
  # makes sure plots display in this order
  group = col_factor(ordered = TRUE),
  term = col_factor(ordered = TRUE)
  )) %>%
  filter(effect == "fixed") %>%
  dplyr::select(term, estimate, std.error, p.value)

# calculate mean estimates and power for specified alpha
alpha <- 0.05

sims %>% 
  group_by(term) %>%
  dplyr::summarize(
    mean_estimate = mean(estimate),
    mean_se = mean(std.error),
    power = mean(p.value < alpha),
    .groups = "drop"
  )
```

After running this model a couple of hundred times, we can converge on values for power that are > .80 - perfect for our little study on the IDS preference effect. However, we should note the limitations in this approach. There are a bunch of assumptions that went into specifying the different parameters, and we need a way to grid search through values to put the power results into perspective. We turn to this problem in the next exercise sheet, but first, let's make sure that we've understood the principles behind data simulation and power analysis.

Exercise 2: Let's explore the effect of repeated measures on power. Try to run a power analysis with each subject receiving two items and another power analysis with each subject receiving 15 items. What happens to the estimate of statistical power?

Write your answer here:

______________________________________________________________________________________________________________


